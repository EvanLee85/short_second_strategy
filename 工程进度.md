按策略文档 V2.1的流程（“宏观过滤 → 六步轮动 → 一线确认 → 二线筛选 → 买点与分时硬校验 → 三闸门净期望 → 仓位/风险 → 卖出剧本 → 熔断/情绪 → 复盘回测”）+ 系统架构，
把工程拆成无时间维度的阶段计划。
每一步都写清楚“目标 / 交付物 / 代码位置 / 需要的库（必选+可选）”。
推荐 Python：3.11.x（与现有脚本、实时通道依赖兼容性最佳）。

工程进度计划（只含步骤）
0. 项目骨架与运行基座

目标：空实现但结构完整，可启动最小后端与静态前端，占位 API 全部有路由。
交付物：

目录树（已建），空文件按 README 命名齐备

backend/app.py 最小化可启动

frontend/index.html 接入占位按钮/区块（先不绑真实数据）
代码位置：backend/*、frontend/*、config/*、scripts/manage.sh
库（必选）：Flask、Flask-Cors、Flask-SocketIO、eventlet、loguru、PyYAML
（可选：click 用于CLI；redis 作为SocketIO多进程消息队列）

1. 宏观 / Regime 动态过滤（“做不做”）

目标：实现“硬条件/软条件”配置与计算管线，返回通过/拦截原因。
交付物：

阈值：backend/config/thresholds.yaml（VIX、期货、MA50、广度、北向等）

计算模块：backend/core/macro_filter.py

数据接入占位：backend/data/fetcher.py（后面逐步接真数据）

API：GET /api/v1/macro/status
库（必选）：pandas、numpy
（可选：requests（取VIX/期货/北向）、pydantic（结果校验））

2. 板块轮动“六步验证”（“做哪个”）

目标：实现成交额排名切换、广度/风格分层、时间延续、资金比例、主力背书、ETF申赎/北向验证与“衰退阈值”。
交付物：

模块：backend/core/sector_rotation.py

API：GET /api/v1/sectors/rotation
库（必选）：pandas、numpy
（可选：requests（ETF/北向/龙虎榜数据）、scipy（相关度/逻辑链评分））

3. 一线龙头确认（“先有灯塔”）

目标：识别板块内一线特征（最先涨停/放量最大、成交额Top1–2、连板/≥+15%、龙虎榜背书），并限制一线≥3板不再起步。
交付物：

模块：backend/core/stock_selector.py（一线识别子模块）

产出：一线候选清单（供二线筛选阶段使用）
库（必选）：pandas
（可选：ta 或 pandas-ta 做量价判定；尽量避免 TA-Lib）

4. 二线龙头筛选（“从候选到目标”）

目标：按策略五大束条件筛选：成交额/市值、位置/形态、资金痕迹、行业分层PE、快筛避雷 + “补涨时序与RS”。
交付物：

模块：backend/core/stock_selector.py（二线筛选主逻辑）

API：GET /api/v1/stocks/leaders?sector=...&type=second-line
库（必选）：pandas、numpy
（可选：ta/pandas-ta、scikit-learn（RS/标准化）、requests（财务/龙虎榜））

5. 买点（四类）与分时硬指标校验（“什么时候进”）

目标：实现四类买点（突破/回踩/分歧转强/强势跟随）与分时硬指标（前2小时量占比≥50%、尾盘突放量占比判警等）；支持AVWAP/ATR/OBV等。
交付物：

模块：backend/core/entry_signals.py

分时流：backend/data/realtime.py（接口占位，后续接实盘源）

API：POST /api/v1/trades/signal（仅回显信号计算结果，不下单）
库（必选）：pandas、numpy
（可选：pandas-ta/ta、numba（加速）、websockets 或 数据商SDK）

6. 三闸门净期望评估（RR / Pwin / EV_net）

目标：下单前强制通过RR最小值、胜率下限、净期望下限三闸门，输出“可下单/拒绝+理由”。
交付物：

模块：backend/core/risk_manager.py（三闸门 + 期望计算）

阈值：thresholds.yaml（rr_min / pwin_min / ev_net_min）

结果写入：logs/trading.log（审计）
库（必选）：pandas、numpy
（可选：scipy/statsmodels（胜率/分布拟合））

7. 仓位与账户风控（单笔风险、总风险、ATR止损、隔夜惩罚）

目标：把单笔风险%与总敞口上限、ATR法止损、隔夜惩罚调整等规则程序化；给出建议手数/仓位。
交付物：

模块：backend/core/risk_manager.py（仓位建议、止损线计算）

配置：thresholds.yaml（single_risk_pct、total_exposure_max、stop_loss_atr 等）
库（必选）：pandas、numpy
（可选：pydantic（参数校验）、matplotlib（风险曲线可视化））

8. 卖出剧本（T1/T2分批、幅度/时间/结构止盈止损、跌停应对）

目标：下单前生成卖出剧本：何时锁利/清仓、结构破位/时间到期、跌停与次日竞价处理、拖尾原则。
交付物：

模块：backend/core/executor.py（仅生成“执行清单”，不真正下单）

记录：写入 logs/trading.log（剧本文本 + 关键价位）
库（必选）：无新增
（可选：jinja2（模板化剧本）、rich（终端彩色输出））

9. 熔断与情绪量化（停手阈值 / 情绪分）

目标：实现日/月停手阈值触发器、情绪评分记录与限制（如月均情绪>5仅做纸面单）。
交付物：

模块：backend/utils/validators.py（阈值触发与记录）

API：GET /api/v1/health 返回当日是否允许交易及原因
库（必选）：pandas
（可选：tinydb/sqlite（轻量持久化），或 SQLAlchemy）

10. 执行清单自动化（盘前/盘中/盘后）

目标：把策略第11节“执行清单”流程化：

盘前：宏观六条 + 六步轮动 + ETF/北向核验 → 一线≤2板？ → 二线筛选五项 + RS → 候选池

盘中：四类买点 + 分时硬指标 + 三闸门 → 卖出剧本写入

盘后：偏差记录 / 情绪分 / 样本库滚动
交付物：

脚本：scripts/manage.sh（增加一键 run-pre / run-intra / run-post）

报告：data/export/daily_report.json|md
库（必选）：PyYAML、loguru
（可选：jinja2、matplotlib）

11. 数据接入层（逐源打通）

目标：对接行情、资金流、龙虎榜、北向、ETF申赎、财务快筛等数据源；提供统一 fetch API。
交付物：

适配器：backend/data/fetcher.py（统一接口，多源兜底）

缓存：backend/data/cache.py（内存/磁盘）
库（可选按需启用）：requests、akshare、tushare、parquet/pyarrow、diskcache 或 joblib

12. 技术指标与量化工具箱

目标：提供 MA/ATR/OBV/AVWAP、RS、广度/涨跌停统计等常用指标，统一到 analysis/*。
交付物：

指标：backend/analysis/technical.py、capital_flow.py、sentiment.py、correlation.py
库（可选）：pandas-ta 或 ta、scipy、statsmodels

13. 回测引擎（含 T+1、涨跌停、费用/滑点、隔夜惩罚）

目标：最先实现事件驱动的日内-日线混合规则（日线择时+分时入场校验的近似化），输出 Sharpe/MaxDD 等；门槛不达标自动提示调参。
交付物：

引擎：backend/backtest/engine.py

指标：backend/backtest/metrics.py

参数搜索：backend/backtest/optimizer.py（简单网格或贝叶斯可选）
库（必选）：pandas、numpy
（可选：numba、scipy、hyperopt/optuna）

14. 前端联调（只读仪表盘 → 交互筛选 → 实时订阅）

目标：

第1层：只读大盘/轮动/候选池/闸门结果

第2层：交互筛选与买点回放

第3层：实时分时订阅（SocketIO）
交付物：

前端：frontend/js/*.js 绑定 /api/v1/* 与 SocketIO
库（前端可选，后端无新增）：socket.io-client（浏览器），或直接原生 fetch

15. 部署与运维（可选）

目标：Docker 化、反向代理、日志/监控、任务调度。
交付物：

config/docker-compose.yml、scripts/deploy.sh|monitor.py|backup.sh
库（可选）：gunicorn（WSGI；可配 --worker-class eventlet）、gevent/gevent-websocket、prometheus_client

汇总依赖（按阶段累计）

核心起步（0→1）：Flask / Flask-Cors / Flask-SocketIO / eventlet / loguru / PyYAML / pandas / numpy
轮动与龙头（2→4）：+ requests（可选）、ta/pandas-ta（可选）
买点与分时（5）：已含；如接实时流，按数据商SDK或 websockets
三闸门与风险（6→7）：已含；可选 scipy/statsmodels
卖出/熔断/执行清单（8→10）：已含；可选 jinja2
数据接入/缓存（11）：按需 akshare/tushare/diskcache/pyarrow
指标工具箱（12）：pandas-ta/ta（至少其一）
回测（13）：可选 numba、optuna
前端（14）：浏览器侧 socket.io-client（前端包，不在 requirements.txt）


真实数据接入讨论结果：
核心思路是：把“真实数据的脏乱差”都关在数据边界里，对上游暴露一个“永远不变的内部协议”。做法分三层：协议 → 适配 → 校验与回归。

1) 冻结一份“内部数据协议”（不可变）

为全系统唯一入口函数（你现在就是 get_ohlcv(...)）规定不可变的返回规范，并写进 README/工程进度里：

索引：DatetimeIndex，已按时间升序去重；要求时区明确（建议 Asia/Shanghai 或统一 naive + 说明）。

列（固定且完整）：open, high, low, close, volume（浮点/整型都可以，但在函数内统一为 float）。

频率：对外保证 '1d' 起步（分钟线进来先在边界层做 resample，再返回日线）。

复权：明确“前复权/后复权/不复权”，写死在配置中（比如默认前复权），并在 FetchMeta 里记录。

缺失处理：边界层负责补齐/丢弃，上层永远拿到干净数据。

代码形态：内部统一成一种（如 002415.SZ 或 002415），映射在边界层完成。

有了这份“冻结协议”，以后无论接 AkShare/TuShare/券商 API，都只能在边界层自我消化，绝不波及策略/风控/回测。

2) 适配器模式（Provider 适配在下、内部协议在上）

每接一个真实源，就写一个 Provider 适配器（只在 backend/data/fetcher.py 内扩展分支），流程固定：

拉原始数据（列名/频率/时区/复权随它怎么来）；

在边界层做统一化：

列名映射：o/h/l/c/v/t → open/high/low/close/volume；

时区/日历：本地化到 Asia/Shanghai 或统一去 tz；补/裁节假日；

频率对齐：分钟→日线先 resample('1D')（收盘=last，高=最大，低=最小，成交量=和）；

复权对齐：若数据是不复权且需要前复权，边界层做复权或用带前复权的端点；

数值类型统一成 float；

去重、升序、剔除全零/全 NA 行。

严格返回内部协议，并返回 FetchMeta（记录 provider/复权/频率/采样范围），便于回溯。

3) 入口即校验（强约束 + 容错）

在 get_ohlcv(...) 返回前执行一套强校验，出错就抛异常（不要把脏数据继续往上游传）：

列集合完全匹配；

索引严格升序、无重复；

high ≥ max(open, close)、low ≤ min(open, close)；

volume ≥ 0；

不允许全 NA；

行数 ≥ 指定最小条数（比如 30 根，保证指标可计算）。

同时保留容错策略（可配置）：

允许少量 NA，并在边界层前向/后向填充；

对极值/坏值做钳制（clip）；

对异常时间戳做剔除或归一（normalize 到午夜）。

4) 合同测试（Contract Tests）先行

给数据层单独建一组“合同测试”（你可以仿照第 11 步的 run_data_tests.py 再加几条断言），只测 接口契约 是否满足，不去关心策略细节。建议覆盖：

形状与列：列名、dtype、索引升序；

频率一致性：请求 '1d' 就必须返回 '1d'；

复权一致性：切换配置后，价格是否按预期变化（例如同一天 close 随前复权改变）；

交易日历：请求某个日期段，首末是否落在交易日/自然日策略一致（先在文档定好）；

稳定性：同一参数短时间重复拉取，数值应一致（容忍毫无意义的小数误差）。

任何新 Provider 在合并到主干前，必须先通过合同测试。这样就不会把源端差异渗透到策略层。

5) 显式“符号映射”与“数据来源记录”

维护一个 symbol_map.yaml：{"002415": "002415.SZ", "600519": "600519.SH"}，Provider 适配器读取后转换；

FetchMeta 保留：provider / adjusted / calendar / tz / cache_key。回测、实盘异常时，能迅速定位来源与变换链路。

6) 指标与策略对“数据协议”的单一依赖

entry_signals / risk_manager / backtester 只能通过 get_ohlcv(...) 取数据；

指标库（第 12 步要做的 indicators.py）只接收协议化后的 DataFrame；

任何“临时在上层修修补补”的需求都要回流到数据边界修，保持上层零变化。

7) 版本化与灰度

在 fetcher.get_ohlcv(provider=...) 里加一个 version 概念（或通过配置管理）：

v1：现有协议；

v2（未来扩展列，如 amount/turnover/adj_factor）时，不要破坏 v1，而是在新分支或可选参数中提供，策略侧按需 opt-in。

新 Provider 先灰度：在测试环境切换配置→跑合同测试→跑一套关键策略验证（golden cases）→再上线。

8) “金样本（Golden）”与回归

保留一份“黄金样本 CSV”（5–10 天真实数据 + 期望计算结果），所有 Provider 必须能在这份样本上得到同样的指标输出；

每次改动数据层或指标层，先跑 golden tests，避免数值漂移。

一句话总结

把“内部数据协议”当作法律，不动如山；所有真实数据源都用适配器 + 清洗 + 强校验去对齐该协议；再用合同测试 + 金样本回归守住边界。这样接任何真实行情，最多只改 fetcher 一处，不会殃及策略、风控、回测等已完成模块。




进展和工程进度差异：
一致的地方（按文档步骤 → 你现在的实现）

1 宏观过滤 → MacroFilter + /api/v1/macro/status（已做）。

2 六步轮动 → SectorRotation + /api/v1/sectors/rotation（已做）。

3 一线确认 / 4 二线筛选 → StockSelector.identify_first_line / second_line + /stocks/leaders（已做）。

5 买点与分时硬校验 → entry_signals.evaluate_signal + /trades/signal（已做）。

6 三闸门（RR/Pwin/EV_net） → RiskManager.evaluate_trade_gates + /risk/evaluate（已做）。

7 仓位/账户风控 → RiskManager.suggest_position + /risk/position（已做）。

8 卖出剧本 → 目前由 RiskManager.build_exit_plan + /risk/exit-plan 生成“执行清单”（功能等价，命名与文档建议的 executor.py 不同，后续可重构）。

与文档不同但不冲突的“新增/改动”

聚合计划 /trades/plan：文档里没强制这一层，但我们新增了“信号+三闸门+仓位+剧本”的一次性聚合，便于前后端联调与测试；它只是组合已有模块，不改变各步骤逻辑。

纸上交易 /paper/*：文档第8～10步要求在“下单前写剧本/执行清单”，我们加了一个极轻量“模拟持仓状态机”，方便你端到端演练，不会影响核心算法；进入条件仍由三闸门/信号控制（decision=ENTER 才建仓）。

模块边界：文档建议把“卖出剧本”放 executor.py（第8步），我们暂时放在 RiskManager 里实现同等功能；后续按计划再把剧本/执行清单抽到专用模块即可，不影响现有 API。

仍未覆盖/计划中的项

9 熔断与情绪量化：目前 /health 只是存活检查，尚未接入“停手阈值/情绪分”的判定；这一项在进度文档里单列（后续再接）。

10 执行清单自动化（盘前/盘中/盘后脚本）、11 数据接入层、12 指标工具箱、13 回测引擎与性能门槛、14 前端联调等：文档后续阶段，暂未动工。

结论：当前实现与文档的“功能顺序与核心门槛”保持一致（0→8 步已按计划具备可测试产物），差异主要是封装位置（把卖出剧本先放在 RiskManager）与便捷层（新增 /trades/plan 聚合、/paper/* 模拟）。这些改动是加法，不会破坏文档既定步骤，也不影响你后续把模块拆回到文档提议的命名与层次。


11-15：
11）数据接入层（逐源打通）

统一行情/资金流/北向/ETF申赎/财务等数据接口与缓存；实现 backend/data/fetcher.py 与 backend/data/cache.py 适配层。 

12）技术指标与量化工具箱

整理 MA/ATR/OBV/AVWAP、RS、广度与情绪等指标到 backend/analysis/*，供策略与回测复用。 

13）回测引擎（完善版）

做成独立引擎：T+1、涨跌停、手续费/滑点、隔夜惩罚、性能门槛与指标评估（Sharpe/MaxDD）；backend/backtest/engine.py|metrics.py|optimizer.py。 

14）前端联调

仪表盘只读 → 交互筛选 → 实时订阅（SocketIO）；前端绑定 /api/v1/* 输出与订阅流。 

15）部署与运维（可选）

Docker 化、反代、日志/监控、任务编排；config/docker-compose.yml、scripts/deploy.sh 等。


----------------------------------------------------------------------------------


第 13 步还没做但建议完成的子项，以及第 13 步之后的后续路线。不给代码，只给清单和说明，便于你确认范围。

第13步（Zipline 接入）尚未完成的内容

1. 多标的/选股回测

    现在只回测 TEST 单一标的。需要扩展 CSV bundle 与算法，使其能一次性回测一组代码（如 AI/新能源板块成分），并按日动态选股或轮动。

    进场逻辑应能对“当日候选池”逐一评估 evaluate_signal + RiskManager，按排名/风险限额挑选若干只。

2. 真实仓位 sizing 接入

    用现成的 RiskManager.position_sizing（或你 /risk/position 的同一公式）替代 Zipline 里“固定 20% 仓位”的简化写法，考虑：账户规模、每笔风险%、ATR 止损距离、最小交易单位、手续费和滑点。

3. MarketSentry 熔断接入

    在 Zipline 算法的每日开盘检查里调用“哨兵”决策（或用等价逻辑），如果触发 halt=True 则当日不下单、已持仓可只做风控减仓/清仓。

4. 结果指标与导出

    用 empyrical-reloaded 计算常见指标（年化收益、Sharpe、最大回撤、胜率、收益回撤比）、导出 equity 曲线与交易明细（CSV/PKL），保存在 var/backtests/<run_id>/。

    最少提供一个“简易报告（JSON + CSV）”。

5. 参数化与命令行封装

    增加一个脚本/命令（或后端路由）能指定：回测起止日期、候选池、策略模式（breakout/follow/reversal）、阈值集（读取 thresholds.yaml 的某 profile）、交易成本假设等。

6. 稳定性与回归测试

    为 13 系列新增的功能补充测试：多标的 ingest、算法能跑完全段、结果文件存在、关键指标字段存在并处于合理范围（不校验具体数值，校验结构和非空）。


----------------------------------------------------------------------------------


第13步之后的路线图

14. 数据适配层对接真实行情

    在 data_provider 抽象下接入你计划使用的 A 股数据源（实时/日线）。保证字段、频率、交易日历与当前内部格式完全对齐（你之前已经搭建好了适配与校验思路）。

    做一套“离线重放”与“在线拉取”的一致性测试，确认真实数据不会破坏已实现的组件。

15. 策略研究与参数寻优

    基于 Zipline 批量回放（多标的、多区间、多阈值），做网格/贝叶斯寻优、滚动/Walk-Forward 验证，产出稳定参数集或分情景参数集（如不同波动/市况下的 profile）。

16. 后端生产化与任务编排

    Flask 换生产部署（gunicorn/uvicorn + Nginx）、环境配置隔离（dev/stage/prod）、任务调度（定时跑选股/回测/哨兵检查），统一日志（结构化 JSON）。

17. 监控与告警

    接口健康、错误率、关键决策（开仓/平仓/熔断触发）落日志并告警；保留“纸上交易”流水到本地 DB（如 SQLite/Postgres）以便回溯。

18. 前端/可视化

    简易页面：展示选股结果、交易计划（进场/止损/目标）、哨兵状态、回测报告与曲线；支持一键触发回测与下载结果。

19. 实盘/仿真对接（可选）

    如果未来接交易接口（仿真/实盘），将“纸上交易”状态机替换为经纪商 API，并把风控与哨兵前置到下单前检查；先从“只读下单建议 + 手工确认”开始最稳妥。

20. 文档与可复现

    完整 README/工程进度与测试手册；一条命令拉起环境、生成数据、跑通所有测试（离线 + 在线）。


------------------------------------------------------------------------------------------------


“数据接入做成可插拔模块”的实现步骤与每步概要（不含代码），按落地顺序排好，做完即可无缝接回测与后端。

1）统一接口定义（providers/base.py）

    目的：所有数据源遵守同一签名与返回格式，避免上层感知差异。

    关键点：fetch_ohlcv(symbol, start, end, freq="1d", adjust="pre")->DataFrame；返回列统一为 open,high,low,close,volume，索引为日期。

    输出：Base 协议/抽象类 + 简短文档注释。

2）配置与优先级（config/data_providers.yaml）

    目的：不改代码即可切换/编排数据源与口径。

    关键点：默认日历 XSHG、默认复权 pre、TTL、数据源优先级（例：akshare > tushare > csv）、阈值（价格差容忍等）。

    输出：可读的 YAML，含每源参数（如 TuShare token 环境变量名）。

3）代码规范映射（normalize.symbol）

    目的：统一内部代码形态（如 002415.XSHE），屏蔽各平台的不同（000063.SZ / ts_code 等）。

    关键点：市场推断、补全交易所后缀、与 Zipline 的 sid/symbol 对齐策略。

    输出：to_internal()/from_internal() 两个小工具函数。

4）交易日历与复权规范（normalize.sessions / normalize.adjust）

    目的：彻底消除 Missing/Extra sessions 报错，保证各源产出的时间轴一致。

    关键点：用 exchange_calendars.get_calendar("XSHG") 生成 sessions，对齐 reindex；停牌日补行（OHLC=前收、volume=0）；默认“前复权”。

    输出：对任意源返回的数据执行同一套“对齐+复权”流程的函数。

5）AkShare 适配器（providers/akshare_provider.py）

    目的：接入真实历史数据主源。

    关键点：调用 API、列名重命名、量纲统一（volume→股）、走第4步的规范化流程；超时/重试。

    输出：可直接返回标准 DataFrame 的 Provider 类。

6）TuShare 适配器（providers/tushare_provider.py）

    目的：作为备源/对比源。

    关键点：token 读取、daily + adj_factor 组合实现“前复权”；规范化与异常处理。

    输出：与 AkShare 同签名的 Provider 类。

7）CSV/Stub 适配器（providers/csv_provider.py）

    目的：保持现有桩/CSV 用例不变，并在无网/限流时兜底。

    关键点：最少依赖；如无复权信息，按 adjust="none" 回传或简单近似；仍走统一规范化。

    输出：兼容你现有的 CSV 数据与 Zipline 写入路径。

    *** Qlib离线数据包 后期作为兜底数据 https://github.com/chenditc/investment_data/releases/download/2025-08-24/qlib_bin.tar.gz

8）多源合并与回退（merge.py）

    目的：主源不全或不新鲜时自动补尾、冲突日选最可信的值，形成“最终曲线”。

    关键点：

        新鲜度：最后交易日与日历对比；

        完整性：必须覆盖所有 sessions；

        冲突：同日 close 差异>阈值时优先主源，记录日志；

        质量分：成交额/极端跳变/停牌标记等综合选择。

    输出：合并后的标准 DataFrame + 冲突/回退日志。

9）本地缓存（cache.py）

    目的：减少重复拉取、加速回测批量读。

    关键点：按 provider/symbol/freq/adjust/start_end.parquet 存储；TTL+SchemaVersion 控制失效；读写 Parquet。

    输出：get/put 两个函数，配合哈希校验与 TTL。

10）统一入口（fetcher.py）

    目的：上层只用一个入口，不直接依赖具体 Provider。

    关键点：读取配置→按优先级逐源拉数→规范化→合并→缓存→返回；暴露

            get_ohlcv(symbol, start, end, freq="1d", adjust="pre")

            write_zipline_csv(symbols, start, end, out_dir)（用于 Zipline sss_csv ingest）

    输出：面向后端与回测的公共 API。

11）Zipline 出口（backtest/zipline_export.py）

    目的：把“统一入口的 DataFrame”写到 data/zipline_csv/，用于 zipline ingest -b sss_csv。

    关键点：列名/日期格式完全匹配 Zipline 的 csvdir_equities 规范；按 XSHG 会话确保长度一致。

    输出：稳定可 ingest 的 CSV 写入函数（替换你现在的 stub 生成点）。

12）错误与告警（exceptions.py + logging）

    目的：定位问题快且不静默失败。

    关键点：自定义 DataSourceError（含 provider、symbol、区间、root_cause）；fetcher 记录：缺失补行数、冲突天数、实际来源占比。

    输出：统一异常类型 + INFO/WARN/ERROR 级别日志。

13）限流与重试（providers 内部）

    目的：外部接口稳定，避免瞬时失败。

    关键点：tenacity 做指数退避；AkShare/TuShare 适配器里封装。

    输出：在网络波动下也能拿到数据或快速回退次源。

14）安全与密钥管理

    目的：不把 token 写死。

    关键点：TuShare token 来自环境变量（配置只指明环境变量名）；在 README 标明。

    输出：简单、可迁移的密钥约定。

15）单元与集成测试（tests/）

    目的：保证“替换数据源”不会破坏上层。

    关键点：

        单元：normalize_sessions_ok、adjust_pre_ok、symbol_map_ok、cache_hit_ok；

        集成：akshare_fetch_ok、tushare_fetch_ok、merge_fallback_ok、zipline_ingest_ok、algo_smoke_ok。

    输出：一次性跑完即可判断通过与否的脚本（只打印通过/失败与原因）。

16）后端对接（最小改动）

    目的：API 读历史数据走新入口。

    关键点：将直接读 CSV 的地方改为 fetcher.get_ohlcv()；Zipline CSV 生成改为 write_zipline_csv()。

    输出：不影响既有接口语义的“无痛替换”。

17）文档与样例

    目的：团队协作与可维护。

    关键点：README 增加“配置说明、运行顺序（先改配置→跑 tests→再跑 zipline ingest）、常见故障（会话不一致/复权口径）”。

    输出：简洁的“使用说明 + 故障排查表”。

验收标准（完成定义）

    任一数据源在 2–3 个月区间可正常返回无缺口的日线，且与 XSHG 会话等长。

    write_zipline_csv 生成的数据可 zipline ingest -b sss_csv 零报错（无 Missing/Extra sessions）。

    切换 data_providers.yaml 的 priority 顺序（例如关闭 akshare，只用 tushare 或 csv）时，上层无需改代码且测试全部通过。

    回测最小策略（你已在 13 步完成的宽松策略）在真实数据与桩数据上均能跑通并产生交易。

    这样做完，你的系统就能平滑切换 AkShare/TuShare/CSV，保证真实数据加入后不会牵一发而动全身。