#!/usr/bin/env python3
"""
åç«¯é›†æˆå¿«é€Ÿéƒ¨ç½²è„šæœ¬ (ä¿®å¤ç‰ˆ)
ä¸€é”®å®Œæˆåç«¯å¯¹æ¥ï¼Œå®ç°"æ— ç—›æ›¿æ¢"

è¿è¡Œæ–¹å¼:
python deploy_backend_integration_fixed.py --csv-path ./data/stocks/ --mode auto

åŠŸèƒ½:
1. è‡ªåŠ¨æ£€æµ‹é¡¹ç›®ç»“æ„
2. é…ç½®åç«¯é›†æˆ
3. éªŒè¯è¿ç§»æ•ˆæœ
4. ç”Ÿæˆéƒ¨ç½²æŠ¥å‘Š
"""

import sys
import argparse
from pathlib import Path
import json
from datetime import datetime
import logging
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

class BackendDeploymentTool:
    """åç«¯é›†æˆéƒ¨ç½²å·¥å…·"""
    
    def __init__(self):
        self.deployment_config = {}
        self.deployment_results = {
            'start_time': datetime.now(),
            'steps_completed': [],
            'steps_failed': [],
            'warnings': [],
            'recommendations': []
        }
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('backend_deployment.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def detect_project_structure(self) -> dict:
        """æ£€æµ‹é¡¹ç›®ç»“æ„"""
        self.logger.info("ğŸ” æ£€æµ‹é¡¹ç›®ç»“æ„...")
        
        structure = {
            'project_root': PROJECT_ROOT,
            'has_data_dir': False,
            'has_backend_modules': False,
            'csv_files_found': [],
            'python_files': [],
            'requirements_file': None
        }
        
        # æ£€æŸ¥æ•°æ®ç›®å½•
        common_data_dirs = ['data', 'datasets', 'stock_data', 'csv_data']
        for dir_name in common_data_dirs:
            data_dir = PROJECT_ROOT / dir_name
            if data_dir.exists():
                structure['has_data_dir'] = True
                structure['data_dir'] = data_dir
                
                # æŸ¥æ‰¾CSVæ–‡ä»¶
                csv_files = list(data_dir.glob("*.csv"))
                structure['csv_files_found'].extend(csv_files)
                break
        
        # æ£€æŸ¥åç«¯æ¨¡å—
        backend_dir = PROJECT_ROOT / 'backend'
        if backend_dir.exists():
            structure['has_backend_modules'] = True
            structure['backend_dir'] = backend_dir
        
        # æŸ¥æ‰¾Pythonæ–‡ä»¶
        py_files = list(PROJECT_ROOT.glob("*.py"))
        py_files.extend(PROJECT_ROOT.glob("**/*.py"))
        structure['python_files'] = py_files[:20]  # é™åˆ¶æ•°é‡
        
        # æŸ¥æ‰¾requirementsæ–‡ä»¶
        for req_file in ['requirements.txt', 'requirements-dev.txt', 'pyproject.toml']:
            req_path = PROJECT_ROOT / req_file
            if req_path.exists():
                structure['requirements_file'] = req_path
                break
        
        self.logger.info(f"   âœ… é¡¹ç›®æ ¹ç›®å½•: {structure['project_root']}")
        self.logger.info(f"   ğŸ“ æ•°æ®ç›®å½•: {'å­˜åœ¨' if structure['has_data_dir'] else 'æœªæ‰¾åˆ°'}")
        self.logger.info(f"   ğŸ“‚ åç«¯æ¨¡å—: {'å­˜åœ¨' if structure['has_backend_modules'] else 'æœªæ‰¾åˆ°'}")
        self.logger.info(f"   ğŸ“„ CSVæ–‡ä»¶: å‘ç° {len(structure['csv_files_found'])} ä¸ª")
        
        return structure
    
    def install_dependencies(self) -> bool:
        """å®‰è£…å¿…è¦ä¾èµ–"""
        self.logger.info("ğŸ“¦ æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–...")
        
        required_packages = [
            'pandas>=1.5.0',
            'numpy>=1.21.0', 
            'python-dateutil>=2.8.0'
        ]
        
        try:
            import subprocess
            
            for package in required_packages:
                try:
                    pkg_name = package.split('>=')[0]
                    __import__(pkg_name)
                    self.logger.info(f"   âœ… {pkg_name}: å·²å®‰è£…")
                except ImportError:
                    self.logger.info(f"   ğŸ“¥ å®‰è£… {package}...")
                    result = subprocess.run([
                        sys.executable, '-m', 'pip', 'install', package
                    ], capture_output=True, text=True)
                    
                    if result.returncode == 0:
                        self.logger.info(f"   âœ… {package}: å®‰è£…æˆåŠŸ")
                    else:
                        self.logger.error(f"   âŒ {package}: å®‰è£…å¤±è´¥")
                        return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"ä¾èµ–å®‰è£…å¼‚å¸¸: {e}")
            return False
    
    def create_backend_modules(self) -> bool:
        """åˆ›å»ºåç«¯æ¨¡å—æ–‡ä»¶"""
        self.logger.info("ğŸ”§ åˆ›å»ºåç«¯æ¨¡å—...")
        
        backend_dir = PROJECT_ROOT / 'backend'
        backend_dir.mkdir(exist_ok=True)
        
        # åˆ›å»º__init__.py
        init_file = backend_dir / '__init__.py'
        if not init_file.exists():
            init_content = '''"""
åç«¯æ•°æ®é›†æˆæ¨¡å—
æä¾›æ— ç—›æ›¿æ¢çš„æ•°æ®æºé›†æˆåŠŸèƒ½
"""

from .data_fetcher_facade import get_ohlcv, configure_data_backend
from .zipline_csv_writer import write_zipline_csv
from .backend_integration import enable_backend_integration, disable_backend_integration

__version__ = "1.0.0"
__all__ = [
    'get_ohlcv', 
    'configure_data_backend',
    'write_zipline_csv',
    'enable_backend_integration',
    'disable_backend_integration'
]
'''
            with open(init_file, 'w', encoding='utf-8') as f:
                f.write(init_content)
            
            self.logger.info(f"   âœ… åˆ›å»º: {init_file}")
        
        # æ£€æŸ¥å¿…è¦æ¨¡å—æ–‡ä»¶
        required_modules = [
            'data_fetcher_facade.py',
            'zipline_csv_writer.py', 
            'backend_integration.py'
        ]
        
        missing_modules = []
        for module in required_modules:
            module_file = backend_dir / module
            if not module_file.exists():
                missing_modules.append(module)
        
        if missing_modules:
            self.logger.warning(f"   âš ï¸  ç¼ºå°‘æ¨¡å—: {missing_modules}")
            self.deployment_results['warnings'].append(f"ç¼ºå°‘åç«¯æ¨¡å—: {missing_modules}")
            return False
        
        self.logger.info("   âœ… åç«¯æ¨¡å—æ£€æŸ¥å®Œæˆ")
        return True
    
    def configure_integration(self, csv_data_path: str, mode: str = 'gradual') -> bool:
        """é…ç½®åç«¯é›†æˆ"""
        self.logger.info(f"âš™ï¸  é…ç½®åç«¯é›†æˆ (æ¨¡å¼: {mode})...")
        
        try:
            # å¯¼å…¥å¿…è¦æ¨¡å—
            from backend.data_fetcher_facade import configure_data_backend
            from backend.backend_integration import enable_backend_integration
            
            # é…ç½®æ•°æ®åç«¯
            configure_data_backend(
                csv_data_path=csv_data_path,
                enable_new_fetcher=True,
                fallback_to_csv=True
            )
            
            # æ ¹æ®æ¨¡å¼å¯ç”¨é›†æˆ
            auto_patch = mode in ['auto', 'aggressive']
            
            enable_backend_integration(
                csv_data_path=csv_data_path,
                auto_patch=auto_patch
            )
            
            self.deployment_config = {
                'csv_data_path': csv_data_path,
                'mode': mode,
                'auto_patch': auto_patch,
                'fallback_enabled': True,
                'deployment_time': datetime.now().isoformat()
            }
            
            self.logger.info("   âœ… åç«¯é›†æˆé…ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"   âŒ é…ç½®å¤±è´¥: {e}")
            return False
    
    def run_verification_tests(self) -> dict:
        """è¿è¡ŒéªŒè¯æµ‹è¯•"""
        self.logger.info("ğŸ§ª è¿è¡ŒéªŒè¯æµ‹è¯•...")
        
        test_results = {
            'data_read_test': False,
            'csv_write_test': False,
            'integration_stats': {},
            'performance_ok': True,
            'errors': []
        }
        
        try:
            # æµ‹è¯•1: æ•°æ®è¯»å–
            self.logger.info("   ğŸ” æµ‹è¯•æ•°æ®è¯»å–...")
            from backend.data_fetcher_facade import get_ohlcv
            
            test_data = get_ohlcv(
                symbol="000001.SZ",
                start_date="2024-01-01",
                end_date="2024-01-10"
            )
            
            if not test_data.empty:
                test_results['data_read_test'] = True
                self.logger.info(f"   âœ… æ•°æ®è¯»å–æˆåŠŸ: {len(test_data)} è¡Œ")
            else:
                self.logger.warning("   âš ï¸  æ•°æ®è¯»å–è¿”å›ç©ºç»“æœ")
            
            # æµ‹è¯•2: CSVç”Ÿæˆ
            self.logger.info("   ğŸ“ æµ‹è¯•CSVç”Ÿæˆ...")
            from backend.zipline_csv_writer import write_zipline_csv
            import tempfile
            
            with tempfile.TemporaryDirectory() as temp_dir:
                result = write_zipline_csv(
                    symbols=["000001.SZ"],
                    output_dir=temp_dir,
                    start_date="2024-01-01",
                    end_date="2024-01-10"
                )
                
                if result['files_generated'] > 0:
                    test_results['csv_write_test'] = True
                    self.logger.info("   âœ… CSVç”ŸæˆæˆåŠŸ")
                else:
                    self.logger.warning("   âš ï¸  CSVç”Ÿæˆæ— è¾“å‡º")
            
            # æµ‹è¯•3: é›†æˆç»Ÿè®¡
            self.logger.info("   ğŸ“Š æ£€æŸ¥é›†æˆç»Ÿè®¡...")
            from backend.backend_integration import get_integration_stats
            
            stats = get_integration_stats()
            test_results['integration_stats'] = stats
            
            # ç®€å•çš„æ€§èƒ½æ£€æŸ¥
            if stats['errors'] > stats.get('read_csv_intercepts', 1) * 0.1:
                test_results['performance_ok'] = False
                test_results['errors'].append("é”™è¯¯ç‡è¿‡é«˜")
            
            self.logger.info("   âœ… éªŒè¯æµ‹è¯•å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"   âŒ éªŒè¯æµ‹è¯•å¼‚å¸¸: {e}")
            test_results['errors'].append(str(e))
        
        return test_results
    
    def generate_integration_example(self, csv_data_path: str) -> bool:
        """ç”Ÿæˆé›†æˆç¤ºä¾‹ä»£ç """
        self.logger.info("ğŸ“ ç”Ÿæˆé›†æˆç¤ºä¾‹ä»£ç ...")
        
        example_code = f'''#!/usr/bin/env python3
"""
åç«¯é›†æˆç¤ºä¾‹ä»£ç 
è‡ªåŠ¨ç”Ÿæˆäº: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

import sys
from pathlib import Path
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

def setup_backend_integration():
    """è®¾ç½®åç«¯é›†æˆ"""
    from backend.backend_integration import enable_backend_integration
    
    # å¯ç”¨åç«¯é›†æˆ
    enable_backend_integration(
        csv_data_path="{csv_data_path}",
        auto_patch=True  # è‡ªåŠ¨patch pandaså‡½æ•°
    )
    
    print("âœ… åç«¯é›†æˆå·²å¯ç”¨")

def example_data_reading():
    """ç¤ºä¾‹: æ•°æ®è¯»å–"""
    # åŸæœ‰ä»£ç å®Œå…¨ä¸å˜ï¼Œè‡ªåŠ¨ä½¿ç”¨æ–°æ•°æ®æºï¼
    data = pd.read_csv("data/000001_SZ.csv")
    print(f"è¯»å–æ•°æ®: {{len(data)}} è¡Œ")
    return data

def example_batch_csv_generation():
    """ç¤ºä¾‹: æ‰¹é‡CSVç”Ÿæˆ"""
    from backend.zipline_csv_writer import write_zipline_csv
    
    symbols = ["000001.SZ", "600000.SH", "000002.SZ"]
    
    result = write_zipline_csv(
        symbols=symbols,
        output_dir="./output/",
        start_date="2024-01-01",
        end_date="2024-03-31",
        overwrite=True
    )
    
    print(f"æ‰¹é‡ç”Ÿæˆå®Œæˆ: {{result['files_generated']}}/{{len(symbols)}}")
    return result

def example_performance_monitoring():
    """ç¤ºä¾‹: æ€§èƒ½ç›‘æ§"""
    from backend.backend_integration import get_integration_stats
    
    stats = get_integration_stats()
    print("æ€§èƒ½ç»Ÿè®¡:")
    print(f"  CSVè¯»å–æ‹¦æˆª: {{stats['read_csv_intercepts']}} æ¬¡")
    print(f"  å›é€€è°ƒç”¨: {{stats['fallback_calls']}} æ¬¡") 
    print(f"  é”™è¯¯æ¬¡æ•°: {{stats['errors']}} æ¬¡")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åç«¯é›†æˆç¤ºä¾‹")
    
    # 1. è®¾ç½®é›†æˆ
    setup_backend_integration()
    
    # 2. ç¤ºä¾‹æ•°æ®è¯»å–
    print("\\nğŸ“Š æ•°æ®è¯»å–ç¤ºä¾‹:")
    try:
        data = example_data_reading()
        print("âœ… æ•°æ®è¯»å–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®è¯»å–å¤±è´¥: {{e}}")
    
    # 3. ç¤ºä¾‹CSVç”Ÿæˆ
    print("\\nğŸ“ CSVç”Ÿæˆç¤ºä¾‹:")
    try:
        result = example_batch_csv_generation()
        print("âœ… CSVç”ŸæˆæˆåŠŸ")
    except Exception as e:
        print(f"âŒ CSVç”Ÿæˆå¤±è´¥: {{e}}")
    
    # 4. æ€§èƒ½ç›‘æ§
    print("\\nğŸ“ˆ æ€§èƒ½ç›‘æ§:")
    example_performance_monitoring()

if __name__ == "__main__":
    main()
'''
        
        try:
            example_file = PROJECT_ROOT / "backend_integration_example.py"
            with open(example_file, 'w', encoding='utf-8') as f:
                f.write(example_code)
            
            self.logger.info(f"   âœ… ç¤ºä¾‹ä»£ç ç”Ÿæˆ: {example_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"   âŒ ç¤ºä¾‹ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    def generate_deployment_report(self, verification_results: dict) -> dict:
        """ç”Ÿæˆéƒ¨ç½²æŠ¥å‘Š"""
        self.logger.info("ğŸ“‹ ç”Ÿæˆéƒ¨ç½²æŠ¥å‘Š...")
        
        self.deployment_results['end_time'] = datetime.now()
        self.deployment_results['duration'] = (
            self.deployment_results['end_time'] - self.deployment_results['start_time']
        ).total_seconds()
        
        report = {
            'deployment_info': {
                'timestamp': self.deployment_results['end_time'].isoformat(),
                'duration_seconds': self.deployment_results['duration'],
                'configuration': self.deployment_config
            },
            'verification_results': verification_results,
            'deployment_status': 'success' if all([
                verification_results['data_read_test'],
                verification_results['csv_write_test'],
                len(verification_results['errors']) == 0
            ]) else 'partial_success',
            'next_steps': [
                "è¿è¡Œç¤ºä¾‹ä»£ç éªŒè¯åŠŸèƒ½: python backend_integration_example.py",
                "åœ¨ç°æœ‰ä»£ç ä¸­æ·»åŠ åç«¯é›†æˆåˆå§‹åŒ–",
                "ç›‘æ§é›†æˆç»Ÿè®¡å’Œæ€§èƒ½æŒ‡æ ‡",
                "é€æ­¥è¿ç§»æ›´å¤šåŠŸèƒ½åˆ°æ–°åç«¯"
            ],
            'recommendations': []
        }
        
        # ç”Ÿæˆå»ºè®®
        if not verification_results['data_read_test']:
            report['recommendations'].append("æ•°æ®è¯»å–æµ‹è¯•å¤±è´¥ï¼Œæ£€æŸ¥æ•°æ®æºé…ç½®")
        
        if not verification_results['csv_write_test']:
            report['recommendations'].append("CSVç”Ÿæˆæµ‹è¯•å¤±è´¥ï¼Œæ£€æŸ¥è¾“å‡ºæƒé™")
        
        if verification_results['errors']:
            report['recommendations'].append(f"è§£å†³éªŒè¯é”™è¯¯: {verification_results['errors']}")
        
        if verification_results.get('integration_stats', {}).get('fallback_calls', 0) > 0:
            report['recommendations'].append("å­˜åœ¨å›é€€è°ƒç”¨ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®æºé…ç½®")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = PROJECT_ROOT / "backend_deployment_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, default=str)
        
        self.logger.info(f"   âœ… éƒ¨ç½²æŠ¥å‘Šä¿å­˜: {report_file}")
        return report
    
    def deploy(self, csv_data_path: str, mode: str = 'gradual') -> bool:
        """æ‰§è¡Œå®Œæ•´éƒ¨ç½²æµç¨‹"""
        self.logger.info("ğŸš€ å¼€å§‹åç«¯é›†æˆéƒ¨ç½²...")
        
        try:
            # æ­¥éª¤1: æ£€æµ‹é¡¹ç›®ç»“æ„
            structure = self.detect_project_structure()
            self.deployment_results['steps_completed'].append('detect_structure')
            
            # æ­¥éª¤2: å®‰è£…ä¾èµ–
            if self.install_dependencies():
                self.deployment_results['steps_completed'].append('install_dependencies')
            else:
                self.deployment_results['steps_failed'].append('install_dependencies')
                return False
            
            # æ­¥éª¤3: åˆ›å»ºåç«¯æ¨¡å—
            if self.create_backend_modules():
                self.deployment_results['steps_completed'].append('create_modules')
            else:
                self.deployment_results['steps_failed'].append('create_modules')
                return False
            
            # æ­¥éª¤4: é…ç½®é›†æˆ
            if self.configure_integration(csv_data_path, mode):
                self.deployment_results['steps_completed'].append('configure_integration')
            else:
                self.deployment_results['steps_failed'].append('configure_integration')
                return False
            
            # æ­¥éª¤5: éªŒè¯æµ‹è¯•
            verification_results = self.run_verification_tests()
            self.deployment_results['steps_completed'].append('verification_tests')
            
            # æ­¥éª¤6: ç”Ÿæˆç¤ºä¾‹
            if self.generate_integration_example(csv_data_path):
                self.deployment_results['steps_completed'].append('generate_examples')
            
            # æ­¥éª¤7: ç”ŸæˆæŠ¥å‘Š
            report = self.generate_deployment_report(verification_results)
            self.deployment_results['steps_completed'].append('generate_report')
            
            # è¾“å‡ºæœ€ç»ˆç»“æœ
            self.logger.info("\n" + "="*60)
            self.logger.info("ğŸ‰ åç«¯é›†æˆéƒ¨ç½²å®Œæˆ!")
            self.logger.info("="*60)
            
            self.logger.info(f"éƒ¨ç½²çŠ¶æ€: {report['deployment_status']}")
            self.logger.info(f"å®Œæˆæ­¥éª¤: {len(self.deployment_results['steps_completed'])}")
            self.logger.info(f"å¤±è´¥æ­¥éª¤: {len(self.deployment_results['steps_failed'])}")
            self.logger.info(f"éƒ¨ç½²è€—æ—¶: {self.deployment_results['duration']:.2f} ç§’")
            
            if verification_results['data_read_test']:
                self.logger.info("âœ… æ•°æ®è¯»å–: æ­£å¸¸")
            else:
                self.logger.info("âŒ æ•°æ®è¯»å–: å¼‚å¸¸")
            
            if verification_results['csv_write_test']:
                self.logger.info("âœ… CSVç”Ÿæˆ: æ­£å¸¸")
            else:
                self.logger.info("âŒ CSVç”Ÿæˆ: å¼‚å¸¸")
            
            if report['recommendations']:
                self.logger.info("\nğŸ’¡ å»ºè®®:")
                for rec in report['recommendations']:
                    self.logger.info(f"   â€¢ {rec}")
            
            self.logger.info("\nğŸ“‹ åç»­æ­¥éª¤:")
            for step in report['next_steps']:
                self.logger.info(f"   â€¢ {step}")
            
            return report['deployment_status'] == 'success'
            
        except Exception as e:
            self.logger.error(f"éƒ¨ç½²è¿‡ç¨‹å¼‚å¸¸: {e}")
            traceback.print_exc()
            return False

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='åç«¯é›†æˆå¿«é€Ÿéƒ¨ç½²å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python deploy_backend_integration_fixed.py --csv-path ./data/stocks/ --mode auto
  python deploy_backend_integration_fixed.py --csv-path ./data/ --mode gradual --verify-only
  python deploy_backend_integration_fixed.py --detect-only

æ¨¡å¼è¯´æ˜:
  gradual  : æ¸è¿›æ¨¡å¼ï¼Œä¸è‡ªåŠ¨patch pandaså‡½æ•°ï¼Œé€‚åˆå¤§å‹é¡¹ç›®
  auto     : è‡ªåŠ¨æ¨¡å¼ï¼Œå…¨é¢å¯ç”¨é›†æˆï¼Œé€‚åˆæ–°é¡¹ç›®
  aggressive: æ¿€è¿›æ¨¡å¼ï¼Œç¦ç”¨å›é€€æœºåˆ¶ï¼Œä»…ç”¨äºæµ‹è¯•
        """
    )
    
    parser.add_argument(
        '--csv-path',
        type=str,
        help='CSVæ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºå›é€€æœºåˆ¶'
    )
    
    parser.add_argument(
        '--mode',
        choices=['gradual', 'auto', 'aggressive'],
        default='gradual',
        help='éƒ¨ç½²æ¨¡å¼ (é»˜è®¤: gradual)'
    )
    
    parser.add_argument(
        '--detect-only',
        action='store_true',
        help='ä»…æ£€æµ‹é¡¹ç›®ç»“æ„ï¼Œä¸æ‰§è¡Œéƒ¨ç½²'
    )
    
    parser.add_argument(
        '--verify-only',
        action='store_true',
        help='ä»…è¿è¡ŒéªŒè¯æµ‹è¯•'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶æ‰§è¡Œï¼Œå¿½ç•¥è­¦å‘Š'
    )
    
    parser.add_argument(
        '--log-level',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)'
    )
    
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.getLogger().setLevel(getattr(logging, args.log_level))
    
    print("=" * 80)
    print("ğŸš€ åç«¯é›†æˆå¿«é€Ÿéƒ¨ç½²å·¥å…·")
    print("=" * 80)
    
    tool = BackendDeploymentTool()
    
    try:
        if args.detect_only:
            # ä»…æ£€æµ‹é¡¹ç›®ç»“æ„
            print("ğŸ” é¡¹ç›®ç»“æ„æ£€æµ‹æ¨¡å¼")
            structure = tool.detect_project_structure()
            
            print("\nğŸ“Š æ£€æµ‹ç»“æœ:")
            print(f"   é¡¹ç›®æ ¹ç›®å½•: {structure['project_root']}")
            print(f"   æ•°æ®ç›®å½•: {'å­˜åœ¨' if structure['has_data_dir'] else 'æœªæ‰¾åˆ°'}")
            print(f"   åç«¯æ¨¡å—: {'å­˜åœ¨' if structure['has_backend_modules'] else 'æœªæ‰¾åˆ°'}")
            print(f"   CSVæ–‡ä»¶: {len(structure['csv_files_found'])} ä¸ª")
            print(f"   Pythonæ–‡ä»¶: {len(structure['python_files'])} ä¸ª")
            
            if not structure['has_data_dir'] and not args.csv_path:
                print("\nâš ï¸  å»ºè®®: æœªæ£€æµ‹åˆ°æ•°æ®ç›®å½•ï¼Œè¯·ä½¿ç”¨ --csv-path æŒ‡å®š")
            
            if not structure['has_backend_modules']:
                print("\nâš ï¸  å»ºè®®: ç¼ºå°‘åç«¯æ¨¡å—ï¼Œéœ€è¦å®Œæ•´éƒ¨ç½²")
            
            return 0
        
        if args.verify_only:
            # ä»…è¿è¡ŒéªŒè¯æµ‹è¯•
            if not args.csv_path:
                print("âŒ éªŒè¯æ¨¡å¼éœ€è¦æŒ‡å®š --csv-path")
                return 1
            
            print("ğŸ§ª éªŒè¯æµ‹è¯•æ¨¡å¼")
            
            # å…ˆé…ç½®é›†æˆ
            if not tool.configure_integration(args.csv_path, args.mode):
                print("âŒ é…ç½®å¤±è´¥ï¼Œæ— æ³•è¿›è¡ŒéªŒè¯")
                return 1
            
            # è¿è¡ŒéªŒè¯
            results = tool.run_verification_tests()
            
            print("\nğŸ“Š éªŒè¯ç»“æœ:")
            print(f"   æ•°æ®è¯»å–: {'âœ…' if results['data_read_test'] else 'âŒ'}")
            print(f"   CSVç”Ÿæˆ: {'âœ…' if results['csv_write_test'] else 'âŒ'}")
            print(f"   é”™è¯¯æ•°é‡: {len(results['errors'])}")
            
            if results['errors']:
                print(f"   é”™è¯¯è¯¦æƒ…: {'; '.join(results['errors'])}")
            
            return 0 if len(results['errors']) == 0 else 1
        
        # å®Œæ•´éƒ¨ç½²æµç¨‹
        if not args.csv_path:
            # å°è¯•è‡ªåŠ¨æ£€æµ‹CSVè·¯å¾„
            structure = tool.detect_project_structure()
            if structure['has_data_dir']:
                args.csv_path = str(structure.get('data_dir', './data/'))
                print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹åˆ°CSVè·¯å¾„: {args.csv_path}")
            else:
                print("âŒ æœªæŒ‡å®šCSVè·¯å¾„ä¸”æ— æ³•è‡ªåŠ¨æ£€æµ‹ï¼Œè¯·ä½¿ç”¨ --csv-path æŒ‡å®š")
                return 1
        
        print(f"ğŸ¯ å¼€å§‹éƒ¨ç½² (æ¨¡å¼: {args.mode}, CSVè·¯å¾„: {args.csv_path})")
        
        # å®‰å…¨æ£€æŸ¥
        if not args.force:
            csv_path = Path(args.csv_path)
            if not csv_path.exists():
                print(f"âš ï¸  è­¦å‘Š: CSVè·¯å¾„ä¸å­˜åœ¨: {csv_path}")
                response = input("ç»§ç»­éƒ¨ç½²? (y/N): ").strip().lower()
                if response not in ['y', 'yes']:
                    print("éƒ¨ç½²å·²å–æ¶ˆ")
                    return 0
        
        # æ‰§è¡Œéƒ¨ç½²
        success = tool.deploy(args.csv_path, args.mode)
        
        if success:
            print("\nğŸ‰ éƒ¨ç½²æˆåŠŸå®Œæˆ!")
            print("\nğŸ“‹ æ¥ä¸‹æ¥å¯ä»¥:")
            print("   1. è¿è¡Œç¤ºä¾‹: python backend_integration_example.py")
            print("   2. æŸ¥çœ‹æŠ¥å‘Š: backend_deployment_report.json")
            print("   3. æ£€æŸ¥æ—¥å¿—: backend_deployment.log")
            return 0
        else:
            print("\nâŒ éƒ¨ç½²æœªå®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
            return 1
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  éƒ¨ç½²è¢«ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        print(f"\nğŸ’¥ éƒ¨ç½²è¿‡ç¨‹å¼‚å¸¸: {e}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())