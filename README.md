# çŸ­å‘¨æœŸé‡åŒ–äº¤æ˜“ç³»ç»Ÿ

ä¸€ä¸ªåŸºäºå¤šæ•°æ®æºçš„é«˜é¢‘é‡åŒ–äº¤æ˜“ç³»ç»Ÿï¼Œæ”¯æŒçµæ´»çš„æ•°æ®æºåˆ‡æ¢ã€å¤æƒå¤„ç†å’ŒZiplineé›†æˆã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

```bash
# å®‰è£…ä¾èµ–
pip install pandas numpy zipline-reloaded akshare tushare

# å…‹éš†é¡¹ç›®
git clone <your-repo-url>
cd short_second_strategy
```

### 2. é…ç½®è®¾ç½®

#### åŸºç¡€é…ç½® (`config/settings.py`)

```python
# æ•°æ®æºé…ç½®
DATA_SOURCES = {
    'akshare': {
        'enabled': True,
        'priority': 1,
        'timeout': 30
    },
    'tushare': {
        'enabled': True,
        'priority': 2,
        'token': 'your_tushare_token_here',  # å¿…é¡»é…ç½®
        'timeout': 30
    }
}

# æ•°æ®å­˜å‚¨è·¯å¾„
DATA_PATHS = {
    'raw_data': './data/raw/',
    'processed_data': './data/processed/', 
    'zipline_data': './data/zipline/'
}

# å¤æƒè®¾ç½®
ADJUSTMENT_CONFIG = {
    'method': 'qfq',  # qfqå‰å¤æƒ, hfqåå¤æƒ, noneä¸å¤æƒ
    'base_date': None  # å¤æƒåŸºå‡†æ—¥æœŸï¼ŒNoneè¡¨ç¤ºæœ€æ–°
}
```

#### ç¯å¢ƒå˜é‡é…ç½® (`.env`)

```bash
# å¤åˆ¶é…ç½®æ¨¡æ¿
cp config/.env.example .env

# ç¼–è¾‘é…ç½®æ–‡ä»¶
TUSHARE_TOKEN=your_tushare_token_here
LOG_LEVEL=INFO
ZIPLINE_ROOT=./data/zipline/
```

### 3. è¿è¡Œé¡ºåº â­

**ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹é¡ºåºæ‰§è¡Œï¼Œé¿å…æ•°æ®ä¸ä¸€è‡´ï¼š**

```bash
# Step 1: é…ç½®éªŒè¯
python scripts/verify_config.py

# Step 2: è¿è¡Œæµ‹è¯•å¥—ä»¶
python tests/run_tests.py

# Step 3: æ•°æ®è·å–ä¸å¤„ç†
python scripts/fetch_data.py --symbols 000001.SZ,600000.SH --start-date 2024-01-01

# Step 4: Ziplineæ•°æ®æ‘„å…¥
python scripts/zipline_ingest.py --bundle custom_bundle

# Step 5: è¿è¡Œç­–ç•¥å›æµ‹
python strategies/run_backtest.py --strategy sample_strategy
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
short_second_strategy/
â”œâ”€â”€ README.md                    # æœ¬æ–‡æ¡£
â”œâ”€â”€ config/                      # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ settings.py             # ä¸»é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ .env.example            # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”‚   â””â”€â”€ logging.conf            # æ—¥å¿—é…ç½®
â”œâ”€â”€ data_sources/                # æ•°æ®æºæ¨¡å—
â”‚   â”œâ”€â”€ akshare_source.py       # Akshareæ•°æ®æº
â”‚   â”œâ”€â”€ tushare_source.py       # Tushareæ•°æ®æº
â”‚   â””â”€â”€ unified_fetcher.py      # ç»Ÿä¸€æ•°æ®è·å–å™¨
â”œâ”€â”€ data_processor/              # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ session_normalizer.py  # ä¼šè¯æ ‡å‡†åŒ–
â”‚   â”œâ”€â”€ price_adjuster.py       # å¤æƒå¤„ç†
â”‚   â””â”€â”€ symbol_mapper.py        # ä»£ç æ˜ å°„
â”œâ”€â”€ backend/                     # åç«¯é›†æˆ
â”‚   â”œâ”€â”€ data_fetcher_facade.py  # æ•°æ®è·å–é—¨é¢
â”‚   â”œâ”€â”€ zipline_csv_writer.py   # CSVç”Ÿæˆå™¨
â”‚   â””â”€â”€ backend_integration.py  # é›†æˆé€‚é…å™¨
â”œâ”€â”€ tests/                       # æµ‹è¯•æ¨¡å—
â”‚   â”œâ”€â”€ run_tests.py            # æµ‹è¯•è¿è¡Œå™¨
â”‚   â”œâ”€â”€ unit_tests.py           # å•å…ƒæµ‹è¯•
â”‚   â””â”€â”€ integration_tests.py    # é›†æˆæµ‹è¯•
â”œâ”€â”€ scripts/                     # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ verify_config.py        # é…ç½®éªŒè¯
â”‚   â”œâ”€â”€ fetch_data.py           # æ•°æ®è·å–
â”‚   â””â”€â”€ zipline_ingest.py       # Ziplineæ‘„å…¥
â”œâ”€â”€ strategies/                  # äº¤æ˜“ç­–ç•¥
â”‚   â”œâ”€â”€ sample_strategy.py      # ç¤ºä¾‹ç­–ç•¥
â”‚   â””â”€â”€ run_backtest.py         # å›æµ‹è¿è¡Œå™¨
â””â”€â”€ docs/                        # æ–‡æ¡£ç›®å½•
    â”œâ”€â”€ API.md                  # APIæ–‡æ¡£
    â”œâ”€â”€ TROUBLESHOOTING.md      # æ•…éšœæ’æŸ¥
    â””â”€â”€ DEVELOPMENT.md          # å¼€å‘æŒ‡å—
```

## âš™ï¸ é…ç½®è¯´æ˜

### æ•°æ®æºé…ç½®

ç³»ç»Ÿæ”¯æŒå¤šä¸ªæ•°æ®æºï¼ŒæŒ‰ä¼˜å…ˆçº§è‡ªåŠ¨åˆ‡æ¢ï¼š

```python
DATA_SOURCES = {
    'akshare': {
        'enabled': True,
        'priority': 1,        # ä¼˜å…ˆçº§ï¼š1æœ€é«˜
        'timeout': 30,        # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
        'rate_limit': 1.0,    # é™æµï¼šæ¯ç§’è¯·æ±‚æ•°
        'retry_times': 3      # å¤±è´¥é‡è¯•æ¬¡æ•°
    },
    'tushare': {
        'enabled': True,
        'priority': 2,
        'token': 'your_token', # Tushare API token
        'timeout': 30,
        'rate_limit': 0.5,     # Tushareé™æµæ›´ä¸¥æ ¼
        'retry_times': 3
    }
}
```

### å¤æƒå¤„ç†é…ç½®

```python
ADJUSTMENT_CONFIG = {
    'method': 'qfq',           # å¤æƒæ–¹å¼
    'base_date': None,         # å¤æƒåŸºå‡†æ—¥æœŸ
    'handle_missing': 'drop',  # ç¼ºå¤±æ•°æ®å¤„ç†æ–¹å¼
    'validate_prices': True    # æ˜¯å¦éªŒè¯ä»·æ ¼å…³ç³»
}

# å¤æƒæ–¹å¼è¯´æ˜ï¼š
# 'qfq' - å‰å¤æƒï¼šä»¥æœ€æ–°ä»·æ ¼ä¸ºåŸºå‡†å‘å‰è°ƒæ•´
# 'hfq' - åå¤æƒï¼šä»¥å†å²ä»·æ ¼ä¸ºåŸºå‡†å‘åè°ƒæ•´  
# 'none' - ä¸å¤æƒï¼šä½¿ç”¨åŸå§‹ä»·æ ¼æ•°æ®
```

### Ziplineé›†æˆé…ç½®

```python
ZIPLINE_CONFIG = {
    'bundle_name': 'custom_bundle',
    'data_frequency': 'daily',
    'calendar': 'SHSZ',        # æ²ªæ·±äº¤æ˜“æ—¥å†
    'start_session': '2020-01-01',
    'end_session': '2024-12-31'
}
```

## ğŸ”§ ä½¿ç”¨è¯´æ˜

### æ•°æ®è·å–

```python
from data_sources.unified_fetcher import UnifiedDataFetcher

# åˆ›å»ºæ•°æ®è·å–å™¨
fetcher = UnifiedDataFetcher()

# è·å–å•åªè‚¡ç¥¨æ•°æ®
data = fetcher.get_stock_data(
    symbol='000001.SZ',
    start_date='2024-01-01',
    end_date='2024-12-31',
    adjust='qfq'  # å‰å¤æƒ
)

# æ‰¹é‡è·å–æ•°æ®
symbols = ['000001.SZ', '600000.SH', '000002.SZ']
batch_data = fetcher.batch_get_data(
    symbols=symbols,
    start_date='2024-01-01',
    end_date='2024-12-31'
)
```

### åç«¯é›†æˆä½¿ç”¨

```python
# å¯ç”¨åç«¯é›†æˆï¼ˆä¸€æ¬¡æ€§è®¾ç½®ï¼‰
from backend.backend_integration import enable_backend_integration

enable_backend_integration(
    csv_data_path='./data/raw/',
    auto_patch=True  # è‡ªåŠ¨patch pandaså‡½æ•°
)

# ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹ï¼Œè‡ªåŠ¨ä½¿ç”¨æ–°æ•°æ®æºï¼
import pandas as pd
data = pd.read_csv('data/000001.SZ.csv')  # è‡ªåŠ¨åˆ‡æ¢åˆ°æ–°æ•°æ®è·å–å™¨
```

### Ziplineç­–ç•¥å¼€å‘

```python
from zipline import run_algorithm
from zipline.api import order_percent, symbol

def initialize(context):
    """ç­–ç•¥åˆå§‹åŒ–"""
    context.asset = symbol('000001.SZ')
    
def handle_data(context, data):
    """æ¯æ—¥å¤„ç†é€»è¾‘"""
    price = data.current(context.asset, 'close')
    
    # ç®€å•çš„ä¹°å…¥æŒæœ‰ç­–ç•¥
    if not context.portfolio.positions[context.asset]:
        order_percent(context.asset, 1.0)

# è¿è¡Œå›æµ‹
result = run_algorithm(
    start='2024-01-01',
    end='2024-12-31',
    initialize=initialize,
    handle_data=handle_data,
    bundle='custom_bundle'
)
```

## ğŸ§ª æµ‹è¯•éªŒè¯

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
python tests/run_tests.py

# è¿è¡Œç‰¹å®šæµ‹è¯•
python tests/unit_tests.py                    # å•å…ƒæµ‹è¯•
python tests/integration_tests.py             # é›†æˆæµ‹è¯•

# éªŒè¯éƒ¨ç½²
python test_deployment.py                     # éƒ¨ç½²éªŒè¯

# æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
python scripts/data_consistency_check.py      # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
```

## ğŸ“Š ç›‘æ§ä¸æ—¥å¿—

### æ—¥å¿—é…ç½®

ç³»ç»Ÿæä¾›è¯¦ç»†çš„æ—¥å¿—è®°å½•ï¼š

```python
import logging

# é…ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/system.log'),
        logging.StreamHandler()
    ]
)
```

### æ€§èƒ½ç›‘æ§

```python
from backend.backend_integration import get_integration_stats

# è·å–é›†æˆç»Ÿè®¡
stats = get_integration_stats()
print(f"æ•°æ®è·å–æ¬¡æ•°: {stats['read_csv_intercepts']}")
print(f"å›é€€æ¬¡æ•°: {stats['fallback_calls']}")
print(f"é”™è¯¯æ¬¡æ•°: {stats['errors']}")
```

## ğŸš¨ å¸¸è§æ•…éšœæ’æŸ¥

### å¿«é€Ÿè¯Šæ–­

```bash
# è¿è¡Œç³»ç»Ÿè¯Šæ–­
python scripts/system_diagnosis.py

# æ£€æŸ¥é…ç½®é—®é¢˜
python scripts/verify_config.py --verbose

# æ•°æ®æºè¿é€šæ€§æµ‹è¯•
python scripts/test_data_sources.py
```

### å¸¸è§é—®é¢˜è§£å†³

#### 1. æ•°æ®æºè¿æ¥å¤±è´¥

**ç°è±¡**: `ConnectionError: æ•°æ®æºè¿æ¥è¶…æ—¶`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping www.baidu.com

# éªŒè¯API token
python scripts/test_data_sources.py --source tushare

# è°ƒæ•´è¶…æ—¶è®¾ç½®
# åœ¨config/settings.pyä¸­å¢åŠ timeoutå€¼
```

#### 2. å¤æƒæ•°æ®ä¸ä¸€è‡´

**ç°è±¡**: åŒä¸€è‚¡ç¥¨ä¸åŒæ—¶é—´è·å–çš„æ•°æ®ä»·æ ¼ä¸åŒ¹é…

**åŸå› **: å¤æƒåŸºå‡†æ—¥æœŸä¸åŒå¯¼è‡´

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç»Ÿä¸€å¤æƒåŸºå‡†
ADJUSTMENT_CONFIG = {
    'method': 'qfq',
    'base_date': '2024-12-31',  # è®¾ç½®å›ºå®šåŸºå‡†æ—¥æœŸ
    'cache_adjustment_factors': True
}

# æ¸…ç†ç¼“å­˜é‡æ–°è·å–
python scripts/clear_cache.py --type adjustment
```

#### 3. ä¼šè¯æ•°æ®ä¸ä¸€è‡´

**ç°è±¡**: äº¤æ˜“æ—¥å†ä¸æ•°æ®æ—¥æœŸä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨æ ‡å‡†äº¤æ˜“æ—¥å†
from zipline.utils.calendars import get_calendar

calendar = get_calendar('SHSZ')  # æ²ªæ·±äº¤æ˜“æ‰€æ—¥å†

# æˆ–æ‰‹åŠ¨æŒ‡å®šäº¤æ˜“æ—¥
TRADING_CALENDAR = {
    'exclude_weekends': True,
    'exclude_holidays': True,
    'custom_holidays': ['2024-01-01', '2024-02-10']  # è‡ªå®šä¹‰å‡æœŸ
}
```

#### 4. Ziplineæ‘„å…¥å¤±è´¥

**ç°è±¡**: `zipline ingest` å‘½ä»¤å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ•°æ®æ ¼å¼
python scripts/validate_zipline_data.py

# æ¸…ç†Ziplineç¼“å­˜
zipline clean --bundle custom_bundle

# é‡æ–°æ‘„å…¥æ•°æ®
python scripts/zipline_ingest.py --bundle custom_bundle --force
```

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### è·å–å¸®åŠ©

- ğŸ“– æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: [docs/](./docs/)
- ğŸ› é—®é¢˜åé¦ˆ: [GitHub Issues](issuesé“¾æ¥)
- ğŸ’¬ æŠ€æœ¯è®¨è®º: [å†…éƒ¨æŠ€æœ¯ç¾¤]

### å¼€å‘ä¸è´¡çŒ®

- ğŸ”§ å¼€å‘æŒ‡å—: [docs/DEVELOPMENT.md](./docs/DEVELOPMENT.md)
- ğŸ§ª æµ‹è¯•æŒ‡å—: [docs/TESTING.md](./docs/TESTING.md)
- ğŸ“‹ ä»£ç è§„èŒƒ: [docs/CODING_STANDARDS.md](./docs/CODING_STANDARDS.md)

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

*æœ€åæ›´æ–°: 2025-08-27*
*ç‰ˆæœ¬: 1.0.0*