#!/usr/bin/env python3
"""
å®Œæ•´çš„åç«¯è¿ç§»ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•å®ç°"æ— ç—›æ›¿æ¢"ï¼Œå°†ç›´æ¥è¯»CSVæ”¹ä¸ºfetcher.get_ohlcv()ï¼Œ
CSVç”Ÿæˆæ”¹ä¸ºwrite_zipline_csv()

è¿è¡Œæ–¹å¼:
python examples/complete_migration_example.py
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import tempfile
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæ¼”ç¤º"""
    print("ğŸ¯ åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•ç»“æ„
    temp_dir = Path("temp_migration_demo")
    temp_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºåŸå§‹æ•°æ®ç›®å½•
    old_data_dir = temp_dir / "old_data"
    old_data_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    new_data_dir = temp_dir / "new_data"
    new_data_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆç¤ºä¾‹è‚¡ç¥¨æ•°æ®
    symbols = ["000001.SZ", "000002.SZ", "600000.SH", "600036.SH"]
    
    for symbol in symbols:
        # ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®
        dates = pd.date_range('2024-01-01', '2024-03-31', freq='D')
        dates = [d for d in dates if d.weekday() < 5]  # åªä¿ç•™å·¥ä½œæ—¥
        
        np.random.seed(hash(symbol) % 2**32)  # ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
        base_price = np.random.uniform(10, 50)
        
        data = []
        current_price = base_price
        
        for date in dates:
            # æ¨¡æ‹Ÿä»·æ ¼å˜åŠ¨
            change = np.random.normal(0, 0.02)  # 2%çš„æ—¥æ³¢åŠ¨ç‡
            current_price *= (1 + change)
            
            open_price = current_price * (1 + np.random.normal(0, 0.005))
            high_price = max(open_price, current_price) * (1 + abs(np.random.normal(0, 0.01)))
            low_price = min(open_price, current_price) * (1 - abs(np.random.normal(0, 0.01)))
            volume = int(np.random.uniform(1000000, 10000000))
            
            data.append({
                'date': date.strftime('%Y-%m-%d'),
                'open': round(open_price, 2),
                'high': round(high_price, 2),
                'low': round(low_price, 2),
                'close': round(current_price, 2),
                'volume': volume
            })
        
        # ä¿å­˜åŸå§‹æ ¼å¼CSV
        df = pd.DataFrame(data)
        csv_file = old_data_dir / f"{symbol.replace('.', '_')}.csv"
        df.to_csv(csv_file, index=False)
        print(f"   âœ… åˆ›å»º {csv_file} ({len(df)} è¡Œ)")
    
    print(f"âœ… ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆï¼Œä½ç½®: {temp_dir}")
    return temp_dir, old_data_dir, new_data_dir

def demonstrate_original_code(old_data_dir):
    """æ¼”ç¤ºåŸå§‹çš„ä»£ç é€»è¾‘"""
    print("\nğŸ“Š æ¼”ç¤ºåŸå§‹ä»£ç é€»è¾‘...")
    
    def original_load_data(symbol):
        """åŸå§‹çš„æ•°æ®åŠ è½½å‡½æ•°"""
        file_path = old_data_dir / f"{symbol.replace('.', '_')}.csv"
        data = pd.read_csv(file_path)
        return data
    
    def original_calculate_indicators(data):
        """åŸå§‹çš„æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
        data = data.copy()
        data['date'] = pd.to_datetime(data['date'])
        data = data.sort_values('date')
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡
        data['sma_20'] = data['close'].rolling(20, min_periods=1).mean()
        data['sma_5'] = data['close'].rolling(5, min_periods=1).mean()
        
        # è®¡ç®—æ”¶ç›Šç‡
        data['daily_return'] = data['close'].pct_change()
        
        return data
    
    def original_batch_process(symbols):
        """åŸå§‹çš„æ‰¹é‡å¤„ç†é€»è¾‘"""
        results = {}
        
        for symbol in symbols:
            try:
                print(f"   å¤„ç† {symbol}...")
                
                # åŸå§‹CSVè¯»å–æ–¹å¼
                data = original_load_data(symbol)
                
                # è®¡ç®—æŒ‡æ ‡
                processed_data = original_calculate_indicators(data)
                
                # ä¿å­˜å¤„ç†ç»“æœ
                output_file = old_data_dir.parent / "processed" / f"{symbol.replace('.', '_')}_processed.csv"
                output_file.parent.mkdir(exist_ok=True)
                processed_data.to_csv(output_file, index=False)
                
                results[symbol] = {
                    'status': 'success',
                    'rows': len(processed_data),
                    'file': str(output_file)
                }
                
            except Exception as e:
                print(f"   âŒ å¤„ç† {symbol} å¤±è´¥: {e}")
                results[symbol] = {'status': 'failed', 'error': str(e)}
        
        return results
    
    # æ‰§è¡ŒåŸå§‹é€»è¾‘
    symbols = ["000001.SZ", "000002.SZ", "600000.SH"]
    results = original_batch_process(symbols)
    
    print(f"   åŸå§‹ä»£ç å¤„ç†ç»“æœ:")
    for symbol, result in results.items():
        if result['status'] == 'success':
            print(f"   âœ… {symbol}: {result['rows']} è¡Œæ•°æ®")
        else:
            print(f"   âŒ {symbol}: {result['error']}")
    
    return results

def demonstrate_migrated_code(old_data_dir, new_data_dir):
    """æ¼”ç¤ºè¿ç§»åçš„ä»£ç """
    print("\nğŸ”„ æ¼”ç¤ºè¿ç§»åçš„ä»£ç ...")
    
    # å¯¼å…¥åç«¯é›†æˆæ¨¡å—
    from backend.backend_integration import enable_backend_integration, read_stock_data, write_stock_csv
    from backend.data_fetcher_facade import get_ohlcv
    from backend.zipline_csv_writer import write_zipline_csv
    
    # å¯ç”¨åç«¯é›†æˆ - è¿™æ˜¯å…³é”®çš„ä¸€æ­¥ï¼
    enable_backend_integration(
        csv_data_path=str(old_data_dir),
        auto_patch=True  # è‡ªåŠ¨patch pandaså‡½æ•°
    )
    
    print("   âœ… åç«¯é›†æˆå·²å¯ç”¨")
    
    def migrated_load_data_v1(symbol):
        """è¿ç§»æ–¹å¼1: å®Œå…¨æ— ä¿®æ”¹ï¼Œè‡ªåŠ¨åˆ‡æ¢"""
        # è¿™é‡Œçš„ä»£ç ä¸åŸå§‹ä»£ç å®Œå…¨ç›¸åŒï¼
        file_path = old_data_dir / f"{symbol.replace('.', '_')}.csv"
        data = pd.read_csv(file_path)  # è¿™é‡Œä¼šè‡ªåŠ¨ä½¿ç”¨æ–°çš„æ•°æ®è·å–å™¨ï¼
        return data
    
    def migrated_load_data_v2(symbol):
        """è¿ç§»æ–¹å¼2: ä½¿ç”¨å…¼å®¹æ€§å‡½æ•°"""
        file_path = old_data_dir / f"{symbol.replace('.', '_')}.csv"
        data = read_stock_data(file_path)  # æ˜¾å¼ä½¿ç”¨æ–°æ¥å£
        return data
    
    def migrated_load_data_v3(symbol):
        """è¿ç§»æ–¹å¼3: ç›´æ¥ä½¿ç”¨æ–°æ¥å£"""
        data = get_ohlcv(
            symbol=symbol,
            start_date="2024-01-01",
            end_date="2024-03-31"
        )
        return data
    
    def migrated_calculate_indicators(data):
        """æŠ€æœ¯æŒ‡æ ‡è®¡ç®—é€»è¾‘å®Œå…¨ä¸å˜"""
        data = data.copy()
        if 'date' in data.columns:
            data['date'] = pd.to_datetime(data['date'])
        data = data.sort_values('date' if 'date' in data.columns else data.columns[0])
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡
        data['sma_20'] = data['close'].rolling(20, min_periods=1).mean()
        data['sma_5'] = data['close'].rolling(5, min_periods=1).mean()
        
        # è®¡ç®—æ”¶ç›Šç‡
        data['daily_return'] = data['close'].pct_change()
        
        return data
    
    def migrated_batch_process_v1(symbols):
        """è¿ç§»æ–¹å¼1: ä»£ç å®Œå…¨ä¸å˜ï¼Œè‡ªåŠ¨ä½¿ç”¨æ–°åç«¯"""
        results = {}
        
        for symbol in symbols:
            try:
                print(f"   å¤„ç† {symbol} (è‡ªåŠ¨åˆ‡æ¢æ¨¡å¼)...")
                
                # è¿™é‡Œçš„ä»£ç ä¸åŸå§‹ç‰ˆæœ¬å®Œå…¨ç›¸åŒï¼
                data = migrated_load_data_v1(symbol)  # è‡ªåŠ¨ä½¿ç”¨æ–°æ•°æ®æº
                processed_data = migrated_calculate_indicators(data)
                
                # ä¿å­˜ç»“æœ
                output_file = new_data_dir / f"{symbol.replace('.', '_')}_v1.csv"
                processed_data.to_csv(output_file, index=False)  # è‡ªåŠ¨ä½¿ç”¨æ–°æ ¼å¼
                
                results[symbol] = {
                    'method': 'auto_switch',
                    'status': 'success', 
                    'rows': len(processed_data),
                    'file': str(output_file)
                }
                
            except Exception as e:
                print(f"   âŒ å¤„ç† {symbol} å¤±è´¥: {e}")
                results[symbol] = {'method': 'auto_switch', 'status': 'failed', 'error': str(e)}
        
        return results
    
    def migrated_batch_process_v2(symbols):
        """è¿ç§»æ–¹å¼2: ä½¿ç”¨æ‰¹é‡æ–°æ¥å£"""
        print(f"   æ‰¹é‡å¤„ç† {len(symbols)} ä¸ªè‚¡ç¥¨ (æ‰¹é‡æ¨¡å¼)...")
        
        try:
            # ç›´æ¥ä½¿ç”¨æ‰¹é‡CSVç”Ÿæˆ
            result = write_zipline_csv(
                symbols=symbols,
                output_dir=str(new_data_dir),
                start_date="2024-01-01",
                end_date="2024-03-31",
                overwrite=True,
                validate=True
            )
            
            print(f"   âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {result['files_generated']}/{len(symbols)}")
            print(f"   â±ï¸  è€—æ—¶: {result.get('duration', 0):.2f} ç§’")
            
            return {
                'method': 'batch_mode',
                'total_symbols': len(symbols),
                'success_count': result['files_generated'],
                'failed_symbols': result.get('failed_symbols', []),
                'duration': result.get('duration', 0)
            }
            
        except Exception as e:
            print(f"   âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            return {'method': 'batch_mode', 'status': 'failed', 'error': str(e)}
    
    # æ‰§è¡Œè¿ç§»åçš„é€»è¾‘
    symbols = ["000001.SZ", "000002.SZ", "600000.SH"]
    
    print("\n   ğŸ”„ æ–¹å¼1: è‡ªåŠ¨åˆ‡æ¢æ¨¡å¼ï¼ˆä»£ç é›¶ä¿®æ”¹ï¼‰")
    results_v1 = migrated_batch_process_v1(symbols)
    
    for symbol, result in results_v1.items():
        if result['status'] == 'success':
            print(f"   âœ… {symbol}: {result['rows']} è¡Œæ•°æ® ({result['method']})")
        else:
            print(f"   âŒ {symbol}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    print("\n   ğŸš€ æ–¹å¼2: æ‰¹é‡å¤„ç†æ¨¡å¼ï¼ˆé«˜æ€§èƒ½ï¼‰")
    results_v2 = migrated_batch_process_v2(symbols)
    
    if results_v2.get('status') != 'failed':
        print(f"   âœ… æ‰¹é‡å¤„ç†: {results_v2['success_count']}/{results_v2['total_symbols']} æˆåŠŸ")
        print(f"   â±ï¸  æ€§èƒ½: {results_v2['duration']:.2f} ç§’")
    else:
        print(f"   âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {results_v2['error']}")
    
    return results_v1, results_v2

def demonstrate_compatibility_check(old_data_dir, new_data_dir):
    """æ¼”ç¤ºå…¼å®¹æ€§æ£€æŸ¥"""
    print("\nğŸ” æ¼”ç¤ºæ•°æ®å…¼å®¹æ€§æ£€æŸ¥...")
    
    def compare_files(original_file, new_file):
        """æ¯”è¾ƒåŸå§‹æ–‡ä»¶å’Œæ–°æ–‡ä»¶çš„å…¼å®¹æ€§"""
        try:
            original_data = pd.read_csv(original_file)
            new_data = pd.read_csv(new_file)
            
            comparison = {
                'original_rows': len(original_data),
                'new_rows': len(new_data),
                'row_diff': len(new_data) - len(original_data),
                'original_cols': list(original_data.columns),
                'new_cols': list(new_data.columns),
                'compatible': True,
                'issues': []
            }
            
            # æ£€æŸ¥è¡Œæ•°å·®å¼‚
            if abs(comparison['row_diff']) > len(original_data) * 0.1:  # 10%å®¹å·®
                comparison['issues'].append(f"è¡Œæ•°å·®å¼‚è¾ƒå¤§: {comparison['row_diff']}")
                comparison['compatible'] = False
            
            # æ£€æŸ¥å¿…è¦åˆ—
            required_cols = ['open', 'high', 'low', 'close', 'volume']
            missing_cols = [col for col in required_cols if col not in new_data.columns]
            if missing_cols:
                comparison['issues'].append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                comparison['compatible'] = False
            
            # æ£€æŸ¥æ•°æ®è´¨é‡
            if 'high' in new_data.columns and 'low' in new_data.columns:
                invalid_prices = (new_data['high'] < new_data['low']).sum()
                if invalid_prices > 0:
                    comparison['issues'].append(f"ä»·æ ¼å…³ç³»å¼‚å¸¸: {invalid_prices} æ¡è®°å½•")
                    comparison['compatible'] = False
            
            return comparison
            
        except Exception as e:
            return {
                'compatible': False,
                'issues': [f"æ¯”è¾ƒå¤±è´¥: {str(e)}"]
            }
    
    # è¿›è¡Œå…¼å®¹æ€§æ£€æŸ¥
    symbols = ["000001.SZ", "000002.SZ"]
    
    for symbol in symbols:
        original_file = old_data_dir / f"{symbol.replace('.', '_')}.csv"
        new_file = new_data_dir / f"{symbol.replace('.', '_')}.csv"
        
        if original_file.exists() and new_file.exists():
            result = compare_files(original_file, new_file)
            
            print(f"   ğŸ“Š {symbol}:")
            print(f"      åŸå§‹æ•°æ®: {result['original_rows']} è¡Œ")
            print(f"      æ–°æ•°æ®: {result['new_rows']} è¡Œ")
            
            if result['compatible']:
                print(f"      âœ… å…¼å®¹æ€§: è‰¯å¥½")
            else:
                print(f"      âš ï¸  å…¼å®¹æ€§é—®é¢˜: {'; '.join(result['issues'])}")
        else:
            print(f"   âŒ {symbol}: æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ£€æŸ¥")

def demonstrate_performance_monitoring():
    """æ¼”ç¤ºæ€§èƒ½ç›‘æ§"""
    print("\nğŸ“ˆ æ¼”ç¤ºæ€§èƒ½ç›‘æ§...")
    
    from backend.backend_integration import get_integration_stats
    
    # è·å–é›†æˆç»Ÿè®¡
    stats = get_integration_stats()
    
    print(f"   ğŸ“Š åç«¯é›†æˆç»Ÿè®¡:")
    print(f"      CSVè¯»å–æ‹¦æˆª: {stats['read_csv_intercepts']} æ¬¡")
    print(f"      CSVå†™å…¥æ‹¦æˆª: {stats['write_csv_intercepts']} æ¬¡")
    print(f"      å›é€€è°ƒç”¨: {stats['fallback_calls']} æ¬¡")
    print(f"      é”™è¯¯æ¬¡æ•°: {stats['errors']} æ¬¡")
    
    # è®¡ç®—æˆåŠŸç‡
    total_operations = stats['read_csv_intercepts'] + stats['write_csv_intercepts']
    if total_operations > 0:
        success_rate = (total_operations - stats['errors']) / total_operations * 100
        fallback_rate = stats['fallback_calls'] / total_operations * 100
        
        print(f"   ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
        print(f"      æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"      å›é€€ç‡: {fallback_rate:.1f}%")
        
        if success_rate >= 95:
            print(f"      âœ… æ€§èƒ½ä¼˜ç§€")
        elif success_rate >= 90:
            print(f"      âš ï¸  æ€§èƒ½è‰¯å¥½ï¼Œå»ºè®®ä¼˜åŒ–")
        else:
            print(f"      âŒ æ€§èƒ½ä¸ä½³ï¼Œéœ€è¦æ’æŸ¥é—®é¢˜")

def cleanup_demo_data(temp_dir):
    """æ¸…ç†æ¼”ç¤ºæ•°æ®"""
    print(f"\nğŸ§¹ æ¸…ç†æ¼”ç¤ºæ•°æ®...")
    
    try:
        import shutil
        if temp_dir.exists():
            shutil.rmtree(temp_dir)
            print(f"   âœ… å·²åˆ é™¤: {temp_dir}")
        else:
            print(f"   â„¹ï¸  ç›®å½•ä¸å­˜åœ¨: {temp_dir}")
    except Exception as e:
        print(f"   âš ï¸  æ¸…ç†å¤±è´¥: {e}")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ åç«¯å¯¹æ¥å®Œæ•´è¿ç§»æ¼”ç¤º")
    print("=" * 80)
    print("ç›®çš„: æ¼”ç¤ºå¦‚ä½•å®ç°'æ— ç—›æ›¿æ¢'")
    print("å…³é”®ç‚¹: å°†ç›´æ¥è¯»CSVæ”¹ä¸ºfetcher.get_ohlcv()ï¼ŒCSVç”Ÿæˆæ”¹ä¸ºwrite_zipline_csv()")
    print("=" * 80)
    
    try:
        # 1. åˆ›å»ºç¤ºä¾‹æ•°æ®
        temp_dir, old_data_dir, new_data_dir = create_sample_data()
        
        # 2. æ¼”ç¤ºåŸå§‹ä»£ç 
        print("\n" + "="*50)
        print("ç¬¬ä¸€éƒ¨åˆ†: åŸå§‹ä»£ç é€»è¾‘")
        print("="*50)
        original_results = demonstrate_original_code(old_data_dir)
        
        # 3. æ¼”ç¤ºè¿ç§»åä»£ç 
        print("\n" + "="*50) 
        print("ç¬¬äºŒéƒ¨åˆ†: è¿ç§»åä»£ç é€»è¾‘")
        print("="*50)
        migrated_results_v1, migrated_results_v2 = demonstrate_migrated_code(old_data_dir, new_data_dir)
        
        # 4. æ¼”ç¤ºå…¼å®¹æ€§æ£€æŸ¥
        print("\n" + "="*50)
        print("ç¬¬ä¸‰éƒ¨åˆ†: å…¼å®¹æ€§æ£€æŸ¥")
        print("="*50)
        demonstrate_compatibility_check(old_data_dir, new_data_dir)
        
        # 5. æ¼”ç¤ºæ€§èƒ½ç›‘æ§
        print("\n" + "="*50)
        print("ç¬¬å››éƒ¨åˆ†: æ€§èƒ½ç›‘æ§")
        print("="*50)
        demonstrate_performance_monitoring()
        
        # 6. æ€»ç»“è¿ç§»æ•ˆæœ
        print("\n" + "="*50)
        print("ğŸ¯ è¿ç§»æ•ˆæœæ€»ç»“")
        print("="*50)
        
        print("âœ… è¿ç§»ä¼˜åŠ¿:")
        print("   1. ä»£ç é›¶ä¿®æ”¹: ç°æœ‰pd.read_csv()è°ƒç”¨è‡ªåŠ¨åˆ‡æ¢åˆ°æ–°æ•°æ®æº")
        print("   2. è‡ªåŠ¨å›é€€: æ–°æ•°æ®æºä¸å¯ç”¨æ—¶è‡ªåŠ¨ä½¿ç”¨åŸCSVæ–‡ä»¶")
        print("   3. æ ¼å¼ç»Ÿä¸€: ç”Ÿæˆçš„CSVæ–‡ä»¶è‡ªåŠ¨ç¬¦åˆZiplineæ ¼å¼è¦æ±‚")
        print("   4. æ€§èƒ½ç›‘æ§: å†…ç½®ç»Ÿè®¡åŠŸèƒ½ï¼Œä¾¿äºç›‘æ§åˆ‡æ¢æ•ˆæœ")
        print("   5. æ¸è¿›è¿ç§»: æ”¯æŒé€æ­¥è¿ç§»ï¼Œé™ä½é£é™©")
        
        print("\nğŸ¯ å…³é”®å®ç°:")
        print("   â€¢ æ•°æ®è¯»å–: pd.read_csv() â†’ è‡ªåŠ¨åˆ‡æ¢åˆ° fetcher.get_ohlcv()")
        print("   â€¢ CSVç”Ÿæˆ: DataFrame.to_csv() â†’ è‡ªåŠ¨ä½¿ç”¨ write_zipline_csv()")
        print("   â€¢ æ— ç—›æ›¿æ¢: ç°æœ‰æ¥å£è¯­ä¹‰å®Œå…¨ä¿æŒä¸å˜")
        
        print("\nğŸ“Š æ¼”ç¤ºç»“æœ:")
        successful_symbols = len([r for r in migrated_results_v1.values() if r.get('status') == 'success'])
        total_symbols = len(migrated_results_v1)
        print(f"   â€¢ è‡ªåŠ¨åˆ‡æ¢æ¨¡å¼: {successful_symbols}/{total_symbols} æˆåŠŸ")
        print(f"   â€¢ æ‰¹é‡å¤„ç†æ¨¡å¼: {migrated_results_v2.get('success_count', 0)} ä¸ªæ–‡ä»¶ç”Ÿæˆ")
        print(f"   â€¢ æ•°æ®æ ¼å¼: å®Œå…¨å…¼å®¹Ziplineè¦æ±‚")
        print(f"   â€¢ è¿ç§»é£é™©: æœ€å°åŒ–ï¼ˆè‡ªåŠ¨å›é€€æœºåˆ¶ï¼‰")
        
        # 7. è¿ç§»å»ºè®®
        print("\nğŸ’¡ å®é™…é¡¹ç›®è¿ç§»å»ºè®®:")
        print("   1. é¦–å…ˆåœ¨å¼€å‘/æµ‹è¯•ç¯å¢ƒéªŒè¯")
        print("   2. å¯ç”¨è¯¦ç»†æ—¥å¿—ç›‘æ§åˆ‡æ¢è¿‡ç¨‹")
        print("   3. å°èŒƒå›´è¯•ç‚¹ï¼Œé€æ­¥æ‰©å¤§èŒƒå›´")  
        print("   4. ä¿æŒåŸCSVæ•°æ®ä½œä¸ºå›é€€æ–¹æ¡ˆ")
        print("   5. å®šæœŸæ£€æŸ¥æ€§èƒ½ç»Ÿè®¡å’Œé”™è¯¯æ—¥å¿—")
        
        print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼ä¸´æ—¶æ–‡ä»¶ä½ç½®: {temp_dir}")
        
        # è¯¢é—®æ˜¯å¦æ¸…ç†
        try:
            response = input("\næ˜¯å¦æ¸…ç†æ¼”ç¤ºæ•°æ®? (y/N): ").strip().lower()
            if response in ['y', 'yes']:
                cleanup_demo_data(temp_dir)
            else:
                print(f"   â„¹ï¸  æ¼”ç¤ºæ•°æ®ä¿ç•™åœ¨: {temp_dir}")
        except (KeyboardInterrupt, EOFError):
            print(f"\n   â„¹ï¸  æ¼”ç¤ºæ•°æ®ä¿ç•™åœ¨: {temp_dir}")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nğŸ’¥ æ¼”ç¤ºè¿‡ç¨‹å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())