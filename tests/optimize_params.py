#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¸²è¡Œå‚æ•°ä¼˜åŒ–è„šæœ¬ï¼šé€šè¿‡ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä½³çš„ç­–ç•¥å‚æ•°ç»„åˆ
"""

import os
import sys
import json
import subprocess
import pathlib
import pandas as pd
import numpy as np
from itertools import product
from datetime import datetime
import pickle
import shutil
from typing import Dict, List, Tuple, Any

# é¡¹ç›®è·¯å¾„è®¾ç½®
PROJ = pathlib.Path(__file__).resolve().parents[1] if "__file__" in globals() else pathlib.Path.cwd()
ZIPLINE_ROOT = PROJ / "var" / "zipline"
CSV_DIR = PROJ / "data" / "zipline_csv"
ALGO_TEMPLATE = PROJ / "backend" / "zipline" / "algo_sss_strategy_relaxed.py"
ALGO_OPTIMIZED = PROJ / "backend" / "zipline" / "algo_sss_optimized.py"
RESULTS_DIR = PROJ / "var" / "optimization_results"

# åˆ›å»ºç»“æœç›®å½•
RESULTS_DIR.mkdir(parents=True, exist_ok=True)

# å‚æ•°æœç´¢ç©ºé—´å®šä¹‰
PARAM_GRID = {
    # ä¿¡å·å‚æ•°
    "lookback": [10, 15, 20, 25],                    # å›çœ‹çª—å£
    "warmup_days": [10, 15, 20],                     # é¢„çƒ­æœŸ
    "vol_ratio": [0.2, 0.3, 0.4, 0.5],              # æˆäº¤é‡æ¯”ç‡é˜ˆå€¼
    "spike_ratio": [0.05, 0.1, 0.15, 0.2],          # ä»·æ ¼spikeé˜ˆå€¼
    
    # ä»“ä½å’Œé£æ§å‚æ•°
    "position_size": [0.15, 0.20, 0.25, 0.30],      # ä»“ä½å¤§å°
    "max_hold_days": [5, 8, 10, 12],                # æœ€å¤§æŒä»“å¤©æ•°
    "take_profit": [3.0, 5.0, 7.0, 10.0],           # æ­¢ç›ˆç™¾åˆ†æ¯”
    "stop_loss": [2.0, 3.0, 5.0],                   # æ­¢æŸç™¾åˆ†æ¯”
    
    # çªç ´å‚æ•°
    "breakout_threshold": [0.98, 0.99, 1.00, 1.01], # çªç ´é˜ˆå€¼ï¼ˆç›¸å¯¹äºå†å²é«˜ç‚¹ï¼‰
    "ma_exit_ratio": [0.97, 0.98, 0.99],            # MAç¦»åœºæ¯”ç‡
}

def generate_strategy_file(params: Dict[str, Any]) -> str:
    """æ ¹æ®å‚æ•°ç”Ÿæˆç­–ç•¥æ–‡ä»¶"""
    
    strategy_code = f'''# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨ç”Ÿæˆçš„ä¼˜åŒ–ç­–ç•¥ - å‚æ•°ç»„åˆæµ‹è¯•
Generated at: {datetime.now()}
Parameters: {json.dumps(params, indent=2)}
"""
from zipline.api import (
    order_target_percent, record, symbol, set_commission, set_slippage,
    schedule_function, date_rules, time_rules, get_datetime
)
from zipline.finance.commission import PerDollar
from zipline.finance.slippage import FixedSlippage
import pandas as pd
import numpy as np

def initialize(context):
    context.asset = symbol("TEST")
    context.lookback = {params['lookback']}
    context.warmup_days_required = {params['warmup_days']}
    context.max_hold_days = {params['max_hold_days']}
    context.position_size = {params['position_size']}
    context.take_profit = {params['take_profit']}
    context.stop_loss = {params['stop_loss']}
    context.breakout_threshold = {params['breakout_threshold']}
    context.ma_exit_ratio = {params['ma_exit_ratio']}
    context.vol_ratio = {params['vol_ratio']}
    context.spike_ratio = {params['spike_ratio']}
    
    context.in_position = False
    context.hold_days = 0
    context.warmup_days = 0
    context.entry_price = None
    
    set_commission(PerDollar(cost=0.0005))
    set_slippage(FixedSlippage(spread=0.0005))
    
    schedule_function(
        rebalance,
        date_rules.every_day(),
        time_rules.market_open(minutes=30)
    )

def simple_breakout_check(hist_df, price, lookback, threshold):
    if len(hist_df) < lookback:
        return False
    recent_high = hist_df['high'].tail(lookback).max()
    return price >= recent_high * threshold

def rebalance(context, data):
    asset = context.asset
    if not data.can_trade(asset):
        return
    
    context.warmup_days += 1
    price = float(data.current(asset, "close"))
    
    try:
        actual_lookback = min(context.lookback, context.warmup_days)
        if actual_lookback < 5:
            record(price=price, in_pos=0)
            return
        
        hist = data.history(asset, ["open", "high", "low", "close", "volume"],
                           actual_lookback, "1d").dropna()
        
        if len(hist) < 5:
            record(price=price, in_pos=0)
            return
    except:
        record(price=price, in_pos=0)
        return
    
    # ä¿¡å·æ£€æµ‹
    sig_pass = False
    if context.warmup_days >= context.warmup_days_required:
        sig_pass = simple_breakout_check(hist, price, 
                                        min(context.lookback, len(hist)), 
                                        context.breakout_threshold)
        
        # é¢å¤–çš„æˆäº¤é‡æ£€æŸ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if sig_pass and len(hist) > 1:
            vol_ratio = hist['volume'].iloc[-1] / hist['volume'].mean()
            if vol_ratio < context.vol_ratio:
                sig_pass = False
    
    # å¼€ä»“é€»è¾‘
    if (not context.in_position) and sig_pass:
        order_target_percent(asset, context.position_size)
        context.in_position = True
        context.hold_days = 0
        context.entry_price = price
    
    # å¹³ä»“é€»è¾‘
    elif context.in_position:
        context.hold_days += 1
        
        if context.entry_price:
            pnl_pct = (price / context.entry_price - 1) * 100
        else:
            pnl_pct = 0
        
        exit_signal = False
        
        # æ­¢ç›ˆ
        if pnl_pct >= context.take_profit:
            exit_signal = True
        # æ­¢æŸ
        elif pnl_pct <= -context.stop_loss:
            exit_signal = True
        # æ—¶é—´æ­¢æŸ
        elif context.hold_days >= context.max_hold_days:
            exit_signal = True
        # MAç¦»åœº
        elif len(hist) >= 10:
            ma10 = float(hist["close"].tail(10).mean())
            if price < ma10 * context.ma_exit_ratio:
                exit_signal = True
        
        if exit_signal:
            order_target_percent(asset, 0.0)
            context.in_position = False
            context.hold_days = 0
            context.entry_price = None
    
    record(price=price, in_pos=int(context.in_position))

def handle_data(context, data):
    pass
'''
    
    # ä¿å­˜ç­–ç•¥æ–‡ä»¶
    with open(ALGO_OPTIMIZED, 'w', encoding='utf-8') as f:
        f.write(strategy_code)
    
    return str(ALGO_OPTIMIZED)

def run_backtest(params: Dict[str, Any]) -> Dict[str, Any]:
    """è¿è¡Œå•æ¬¡å›æµ‹"""
    
    # ç”Ÿæˆç­–ç•¥æ–‡ä»¶
    algo_file = generate_strategy_file(params)
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    out_pkl = ZIPLINE_ROOT / f"opt_perf_{timestamp}.pkl"
    
    # ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env["ZIPLINE_ROOT"] = str(ZIPLINE_ROOT)
    env["CSVDIR"] = str(CSV_DIR)
    env["PYTHONPATH"] = f"{PROJ}:{env.get('PYTHONPATH','')}"
    
    # è¿è¡Œå›æµ‹å‘½ä»¤
    args = [
        "zipline", "run",
        "-f", algo_file,
        "-b", "sss_csv",
        "--start", "2024-02-05",
        "--end", "2024-03-29",
        "--capital-base", "100000",
        "--data-frequency", "daily",
        "--no-benchmark",
        "-o", str(out_pkl),
    ]
    
    try:
        result = subprocess.run(args, env=env, capture_output=True, text=True, timeout=60)
        
        if result.returncode != 0:
            print(f"âœ— Backtest failed for params: {params}")
            return {"success": False, "error": result.stderr}
        
        # è¯»å–ç»“æœ
        perf = pd.read_pickle(out_pkl)
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        returns = perf['returns']
        total_return = (perf['portfolio_value'].iloc[-1] / 100000 - 1) * 100
        
        # è®¡ç®—å¤æ™®æ¯”ç‡
        if returns.std() > 0:
            sharpe = returns.mean() / returns.std() * np.sqrt(252)
        else:
            sharpe = 0
        
        # è®¡ç®—æœ€å¤§å›æ’¤
        cum_returns = (1 + returns).cumprod()
        running_max = cum_returns.expanding().max()
        drawdown = (cum_returns - running_max) / running_max
        max_drawdown = drawdown.min() * 100
        
        # äº¤æ˜“ç»Ÿè®¡
        n_transactions = sum(len(x) for x in perf.get("transactions", []))
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if out_pkl.exists():
            out_pkl.unlink()
        
        return {
            "success": True,
            "total_return": total_return,
            "sharpe_ratio": sharpe,
            "max_drawdown": max_drawdown,
            "n_transactions": n_transactions,
            "final_value": perf['portfolio_value'].iloc[-1],
            "params": params
        }
        
    except subprocess.TimeoutExpired:
        print(f"âœ— Backtest timeout for params: {params}")
        return {"success": False, "error": "Timeout"}
    except Exception as e:
        print(f"âœ— Error in backtest: {e}")
        return {"success": False, "error": str(e)}

def optimize_parameters():
    """æ‰§è¡Œå‚æ•°ä¼˜åŒ–"""
    
    print("=" * 60)
    print("ç­–ç•¥å‚æ•°ä¼˜åŒ–å¼€å§‹")
    print("=" * 60)
    
    # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
    param_names = list(PARAM_GRID.keys())
    param_values = list(PARAM_GRID.values())
    all_combinations = list(product(*param_values))
    
    total_combinations = len(all_combinations)
    print(f"æ€»å…±éœ€è¦æµ‹è¯• {total_combinations} ç§å‚æ•°ç»„åˆ")
    print("è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...\n")
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    results = []
    
    # æµ‹è¯•æ¯ç§ç»„åˆ
    for i, combination in enumerate(all_combinations, 1):
        params = dict(zip(param_names, combination))
        
        print(f"[{i}/{total_combinations}] æµ‹è¯•å‚æ•°ç»„åˆ...")
        
        result = run_backtest(params)
        
        if result["success"]:
            results.append(result)
            print(f"  âœ“ æ”¶ç›Šç‡: {result['total_return']:.2f}%, "
                  f"å¤æ™®: {result['sharpe_ratio']:.2f}, "
                  f"æœ€å¤§å›æ’¤: {result['max_drawdown']:.2f}%, "
                  f"äº¤æ˜“æ¬¡æ•°: {result['n_transactions']}")
        else:
            print(f"  âœ— å¤±è´¥: {result.get('error', 'Unknown error')}")
        
        # æ¯10æ¬¡ä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœ
        if i % 10 == 0:
            save_intermediate_results(results)
    
    return results

def save_intermediate_results(results: List[Dict]):
    """ä¿å­˜ä¸­é—´ç»“æœ"""
    if results:
        df = pd.DataFrame(results)
        df.to_csv(RESULTS_DIR / "intermediate_results.csv", index=False)

def analyze_results(results: List[Dict]):
    """åˆ†æä¼˜åŒ–ç»“æœ"""
    
    if not results:
        print("æ²¡æœ‰æˆåŠŸçš„å›æµ‹ç»“æœ")
        return
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(results)
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    df.to_csv(RESULTS_DIR / "optimization_results.csv", index=False)
    
    print("\n" + "=" * 60)
    print("ä¼˜åŒ–ç»“æœåˆ†æ")
    print("=" * 60)
    
    # æŒ‰ä¸åŒæŒ‡æ ‡æ’åºå¹¶æ˜¾ç¤ºå‰5å
    print("\nğŸ“ˆ æŒ‰æ€»æ”¶ç›Šç‡æ’åºï¼ˆå‰5åï¼‰:")
    top_return = df.nlargest(5, 'total_return')
    for idx, row in top_return.iterrows():
        print(f"\næ”¶ç›Šç‡: {row['total_return']:.2f}%")
        print(f"å¤æ™®æ¯”ç‡: {row['sharpe_ratio']:.2f}")
        print(f"æœ€å¤§å›æ’¤: {row['max_drawdown']:.2f}%")
        print(f"äº¤æ˜“æ¬¡æ•°: {row['n_transactions']}")
        print(f"å‚æ•°: {json.dumps(row['params'], indent=2)}")
        print("-" * 40)
    
    print("\nğŸ“Š æŒ‰å¤æ™®æ¯”ç‡æ’åºï¼ˆå‰5åï¼‰:")
    top_sharpe = df.nlargest(5, 'sharpe_ratio')
    for idx, row in top_sharpe.head(3).iterrows():
        print(f"\nå¤æ™®æ¯”ç‡: {row['sharpe_ratio']:.2f}")
        print(f"æ”¶ç›Šç‡: {row['total_return']:.2f}%")
        print(f"å‚æ•°: {json.dumps(row['params'], indent=2)}")
    
    print("\nğŸ’ ç»¼åˆè¯„åˆ†æœ€ä½³ï¼ˆè€ƒè™‘æ”¶ç›Šã€å¤æ™®ã€å›æ’¤ï¼‰:")
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    df['score'] = (
        df['total_return'] * 0.4 +  # 40% æƒé‡ç»™æ”¶ç›Š
        df['sharpe_ratio'] * 10 * 0.3 +  # 30% æƒé‡ç»™å¤æ™®
        (-df['max_drawdown']) * 0.3  # 30% æƒé‡ç»™å›æ’¤æ§åˆ¶
    )
    
    best_overall = df.nlargest(1, 'score').iloc[0]
    print(f"\næœ€ä½³å‚æ•°ç»„åˆ:")
    print(f"ç»¼åˆè¯„åˆ†: {best_overall['score']:.2f}")
    print(f"æ”¶ç›Šç‡: {best_overall['total_return']:.2f}%")
    print(f"å¤æ™®æ¯”ç‡: {best_overall['sharpe_ratio']:.2f}")
    print(f"æœ€å¤§å›æ’¤: {best_overall['max_drawdown']:.2f}%")
    print(f"äº¤æ˜“æ¬¡æ•°: {best_overall['n_transactions']}")
    print(f"\næœ€ä½³å‚æ•°é…ç½®:")
    print(json.dumps(best_overall['params'], indent=2))
    
    # ä¿å­˜æœ€ä½³å‚æ•°
    with open(RESULTS_DIR / "best_params.json", 'w') as f:
        json.dump({
            "params": best_overall['params'],
            "metrics": {
                "total_return": best_overall['total_return'],
                "sharpe_ratio": best_overall['sharpe_ratio'],
                "max_drawdown": best_overall['max_drawdown'],
                "n_transactions": int(best_overall['n_transactions']),
                "score": best_overall['score']
            }
        }, f, indent=2)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {RESULTS_DIR}")
    print(f"  - å®Œæ•´ç»“æœ: optimization_results.csv")
    print(f"  - æœ€ä½³å‚æ•°: best_params.json")
    
    return best_overall

def quick_test():
    """å¿«é€Ÿæµ‹è¯•æ¨¡å¼ - åªæµ‹è¯•å°‘é‡å‚æ•°ç»„åˆ"""
    
    # ç®€åŒ–çš„å‚æ•°ç½‘æ ¼
    quick_grid = {
        "lookback": [15, 20],
        "warmup_days": [10, 15],
        "vol_ratio": [0.3, 0.4],
        "spike_ratio": [0.1, 0.15],
        "position_size": [0.20, 0.25],
        "max_hold_days": [8, 10],
        "take_profit": [5.0, 7.0],
        "stop_loss": [3.0],
        "breakout_threshold": [0.99, 1.00],
        "ma_exit_ratio": [0.98],
    }
    
    global PARAM_GRID
    PARAM_GRID = quick_grid
    
    print("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼ - ä½¿ç”¨ç®€åŒ–å‚æ•°é›†")
    results = optimize_parameters()
    best = analyze_results(results)
    return best

def main():
    """ä¸»å‡½æ•°"""
    
    import argparse
    parser = argparse.ArgumentParser(description='ç­–ç•¥å‚æ•°ä¼˜åŒ–å·¥å…·')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆå°‘é‡å‚æ•°ï¼‰')
    parser.add_argument('--full', action='store_true', help='å®Œæ•´ä¼˜åŒ–æ¨¡å¼ï¼ˆæ‰€æœ‰å‚æ•°ï¼‰')
    args = parser.parse_args()
    
    if args.quick:
        quick_test()
    elif args.full:
        results = optimize_parameters()
        analyze_results(results)
    else:
        print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
        print("  --quick  å¿«é€Ÿæµ‹è¯•ï¼ˆçº¦æµ‹è¯•32ç§ç»„åˆï¼‰")
        print("  --full   å®Œæ•´ä¼˜åŒ–ï¼ˆçº¦æµ‹è¯•æ•°ç™¾ç§ç»„åˆï¼‰")
        print("\næ¨èå…ˆè¿è¡Œ: python optimize_params.py --quick")

if __name__ == "__main__":
    main()